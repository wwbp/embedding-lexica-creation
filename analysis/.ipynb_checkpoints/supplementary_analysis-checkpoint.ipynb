{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "executed-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "interracial-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"Generalization results.csv\")\n",
    "methods = results.Method.unique()\n",
    "methods = np.delete(methods, [2,-1])\n",
    "methods = np.insert(methods, [0,2], ['Univariant', 'LSTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "integral-family",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Univariant', 'SVM_STI', 'FFN_STI', 'LSTM', 'DistilBERT_Mask',\n",
       "       'DistilBERT_Partition', 'Roberta_Mask', 'Roberta_Partition'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-sierra",
   "metadata": {},
   "source": [
    "#### t-Test for Model V.S. Lexica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "inappropriate-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_modelvslexica(results):\n",
    "    p = {}\n",
    "    for i in range(len(methods)):\n",
    "        if methods[i] not in p:\n",
    "            p[methods[i]] = []\n",
    "        data = results[results[\"Method\"] == methods[i]]\n",
    "        datawithin = data[data.Within == True]\n",
    "        dataacross = data[data.Within == False]\n",
    "        p[methods[i]].append(stats.ttest_rel(datawithin[\"modelAcc\"],datawithin[\"lexiconAcc\"]).pvalue)\n",
    "        p[methods[i]].append(stats.ttest_rel(datawithin[\"modelF1\"],datawithin[\"lexiconF1\"]).pvalue)\n",
    "        p[methods[i]].append(stats.ttest_rel(dataacross[\"modelAcc\"],dataacross[\"lexiconAcc\"]).pvalue)\n",
    "        p[methods[i]].append(stats.ttest_rel(dataacross[\"modelF1\"],dataacross[\"lexiconF1\"]).pvalue)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "measured-nightmare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Univariant': [nan, nan, nan, nan], 'SVM_STI': [0.483536348156421, 0.4439706063629554, 0.18482340526398236, 0.32711848344560224], 'FFN_STI': [0.06452238268288872, 0.08939581647810328, 0.3048566780875831, 0.17273981730945034], 'LSTM': [0.02634960922789249, 0.0188141532910034, 0.00707622558267093, 0.0007452356279502401], 'DistilBERT_Mask': [0.016449213365099642, 0.013542611993293154, 5.4659316604774427e-14, 3.3807825982632305e-11], 'DistilBERT_Partition': [0.006439138543712099, 0.0038272212355000422, 5.605942117021118e-13, 2.0260173900466587e-10], 'Roberta_Mask': [0.012285540142678663, 0.0106169748599422, 3.766880353512135e-17, 1.0035959318837804e-14], 'Roberta_Partition': [0.004683999299350626, 0.0030404081180523354, 4.8797319029958e-13, 8.072221094433011e-11]}\n"
     ]
    }
   ],
   "source": [
    "# Sentiment\n",
    "results_sentiment = results.copy()\n",
    "results_sentiment = results_sentiment[(results_sentiment.TrainData=='yelp_subset')|(results_sentiment.TrainData=='amazon_toys_subset')|(results_sentiment.TrainData=='amazon_finefood_subset')|(results_sentiment.TrainData=='nrc_joy')]\n",
    "t_test_modelvslexica(results_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "common-greeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Univariant': [nan, nan, nan, nan], 'SVM_STI': [0.028262693007284113, 0.024921827605154115, 0.0844516070959825, 0.3065791571053486], 'FFN_STI': [0.10116200262759636, 0.11433991514645175, 0.2928181895177969, 0.3830318545000383], 'LSTM': [0.01696843422797474, 0.013257600756537539, 0.005162388127066363, 0.017308004838682774], 'DistilBERT_Mask': [0.0005456490520456829, 0.002667047013928404, 0.0006955100080874829, 0.0003498791874349478], 'DistilBERT_Partition': [0.004006703268753135, 0.015075340917638697, 0.0056749271657337, 0.0033407116130359424], 'Roberta_Mask': [0.00030950468050543265, 0.0006551457189938323, 1.5788718383282994e-05, 8.108211046669808e-05], 'Roberta_Partition': [0.0007464200847908984, 0.0017341130816598573, 0.005387903185384761, 0.0022788885758447874]}\n"
     ]
    }
   ],
   "source": [
    "# Emotion\n",
    "results_emotion = results.copy()\n",
    "results_emotion = results_emotion[(results_emotion.TrainData=='nrc_joy')|(results_emotion.TrainData=='nrc_surprise')|(results_emotion.TrainData=='nrc_sadness')|(results_emotion.TrainData=='nrc_fear')|(results_emotion.TrainData=='nrc_anger')]\n",
    "results_emotion = results_emotion.drop(results_emotion[(results_emotion.TestData=='yelp_subset')|(results_emotion.TestData=='amazon_toys_subset')|(results_emotion.TestData=='amazon_finefood_subset')|(results_emotion.TestData=='emobank')].index)\n",
    "t_test_modelvslexica(results_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "demonstrated-mobility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Univariant': [nan, nan, nan, nan], 'SVM_STI': [0.05109532048718469, 0.04437589691108549, 0.03257409136066624, 0.14226044441105698], 'FFN_STI': [0.030528574689970275, 0.040294578327530896, 0.05658807911067907, 0.5483150726726036], 'LSTM': [0.008350403698850465, 0.005433631290250512, 0.00018820489183098493, 7.74265455500235e-05], 'DistilBERT_Mask': [8.66742173141599e-05, 9.854115061782467e-05, 5.91901090027749e-14, 3.9105099598676206e-13], 'DistilBERT_Partition': [5.5356881205732756e-05, 0.0005061847371431916, 1.6846759521145097e-11, 5.495693887076155e-11], 'Roberta_Mask': [2.4065614906026336e-05, 2.2181383340976627e-05, 1.94262837513625e-17, 1.741220656675822e-16], 'Roberta_Partition': [7.030222197569359e-06, 1.148420378965698e-05, 5.8110644306504645e-12, 7.476927384028798e-12]}\n"
     ]
    }
   ],
   "source": [
    "# All\n",
    "t_test_modelvslexica(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "planned-algeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=3.188945818951313, pvalue=0.0024650577850295115)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(results_sentiment[results_sentiment.Method=='LSTM']['lexiconAcc'],results_emotion[results_emotion.Method=='LSTM']['lexiconAcc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-salmon",
   "metadata": {},
   "source": [
    "#### t-Test for Models and Lexicon Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "western-sphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariant-SVM_STI nan\n",
      "Univariant-FFN_STI nan\n",
      "Univariant-LSTM nan\n",
      "Univariant-DistilBERT_Mask nan\n",
      "Univariant-DistilBERT_Partition nan\n",
      "Univariant-Roberta_Mask nan\n",
      "Univariant-Roberta_Partition nan\n",
      "SVM_STI-FFN_STI 0.5485945561365608\n",
      "SVM_STI-LSTM 0.014432847154870287\n",
      "SVM_STI-DistilBERT_Mask 0.001938154641953877\n",
      "SVM_STI-DistilBERT_Partition 0.001938154641953877\n",
      "SVM_STI-Roberta_Mask 3.6854235994048945e-05\n",
      "SVM_STI-Roberta_Partition 3.6854235994048945e-05\n",
      "FFN_STI-LSTM 0.01701878355647658\n",
      "FFN_STI-DistilBERT_Mask 0.002591144891309217\n",
      "FFN_STI-DistilBERT_Partition 0.002591144891309217\n",
      "FFN_STI-Roberta_Mask 6.531937625472047e-05\n",
      "FFN_STI-Roberta_Partition 6.531937625472047e-05\n",
      "LSTM-DistilBERT_Mask 0.09509669494675396\n",
      "LSTM-DistilBERT_Partition 0.09509669494675396\n",
      "LSTM-Roberta_Mask 0.21977258588567028\n",
      "LSTM-Roberta_Partition 0.21977258588567028\n",
      "DistilBERT_Mask-DistilBERT_Partition nan\n",
      "DistilBERT_Mask-Roberta_Mask 6.70223730681591e-05\n",
      "DistilBERT_Mask-Roberta_Partition 6.70223730681591e-05\n",
      "DistilBERT_Partition-Roberta_Mask 6.70223730681591e-05\n",
      "DistilBERT_Partition-Roberta_Partition 6.70223730681591e-05\n",
      "Roberta_Mask-Roberta_Partition nan\n",
      "Univariant-SVM_STI nan\n",
      "Univariant-FFN_STI nan\n",
      "Univariant-LSTM nan\n",
      "Univariant-DistilBERT_Mask nan\n",
      "Univariant-DistilBERT_Partition nan\n",
      "Univariant-Roberta_Mask nan\n",
      "Univariant-Roberta_Partition nan\n",
      "SVM_STI-FFN_STI 0.004748884986639316\n",
      "SVM_STI-LSTM 0.011639706295014965\n",
      "SVM_STI-DistilBERT_Mask 2.041531094768776e-11\n",
      "SVM_STI-DistilBERT_Partition 2.041531094768776e-11\n",
      "SVM_STI-Roberta_Mask 4.676156888187891e-12\n",
      "SVM_STI-Roberta_Partition 4.676156888187891e-12\n",
      "FFN_STI-LSTM 0.7299441389930283\n",
      "FFN_STI-DistilBERT_Mask 9.495483058296521e-14\n",
      "FFN_STI-DistilBERT_Partition 9.495483058296521e-14\n",
      "FFN_STI-Roberta_Mask 1.457881839198438e-11\n",
      "FFN_STI-Roberta_Partition 1.457881839198438e-11\n",
      "LSTM-DistilBERT_Mask 1.033379617039304e-10\n",
      "LSTM-DistilBERT_Partition 1.033379617039304e-10\n",
      "LSTM-Roberta_Mask 1.2449634956552166e-11\n",
      "LSTM-Roberta_Partition 1.2449634956552166e-11\n",
      "DistilBERT_Mask-DistilBERT_Partition nan\n",
      "DistilBERT_Mask-Roberta_Mask 0.0069552615625445334\n",
      "DistilBERT_Mask-Roberta_Partition 0.0069552615625445334\n",
      "DistilBERT_Partition-Roberta_Mask 0.0069552615625445334\n",
      "DistilBERT_Partition-Roberta_Partition 0.0069552615625445334\n",
      "Roberta_Mask-Roberta_Partition nan\n",
      "Univariant-SVM_STI 0.0014056024196088027\n",
      "Univariant-FFN_STI 0.005722839197599758\n",
      "Univariant-LSTM 0.0007501367457990225\n",
      "Univariant-DistilBERT_Mask 0.004301362591414682\n",
      "Univariant-DistilBERT_Partition 0.03289011266394374\n",
      "Univariant-Roberta_Mask 0.0055987917088866496\n",
      "Univariant-Roberta_Partition 6.116834032358895e-06\n",
      "SVM_STI-FFN_STI 0.005647056840610977\n",
      "SVM_STI-LSTM 0.008217714784347492\n",
      "SVM_STI-DistilBERT_Mask 0.06536793800277071\n",
      "SVM_STI-DistilBERT_Partition 0.06436519640006957\n",
      "SVM_STI-Roberta_Mask 0.04446012256293392\n",
      "SVM_STI-Roberta_Partition 0.5500038895408775\n",
      "FFN_STI-LSTM 0.3642689087369484\n",
      "FFN_STI-DistilBERT_Mask 0.8568004846707494\n",
      "FFN_STI-DistilBERT_Partition 0.34429891762944587\n",
      "FFN_STI-Roberta_Mask 0.36298533650923387\n",
      "FFN_STI-Roberta_Partition 0.1987855964287872\n",
      "LSTM-DistilBERT_Mask 0.5331663574350349\n",
      "LSTM-DistilBERT_Partition 0.5040438469090209\n",
      "LSTM-Roberta_Mask 0.8529799473124826\n",
      "LSTM-Roberta_Partition 0.0029804332875111067\n",
      "DistilBERT_Mask-DistilBERT_Partition 0.11565051131300563\n",
      "DistilBERT_Mask-Roberta_Mask 0.34927905424563005\n",
      "DistilBERT_Mask-Roberta_Partition 0.16293591732690763\n",
      "DistilBERT_Partition-Roberta_Mask 0.579214255778255\n",
      "DistilBERT_Partition-Roberta_Partition 0.05186941619066852\n",
      "Roberta_Mask-Roberta_Partition 0.029007933659149\n",
      "Univariant-SVM_STI 2.9627995676663782e-08\n",
      "Univariant-FFN_STI 0.00023460017834162238\n",
      "Univariant-LSTM 0.6102734701619092\n",
      "Univariant-DistilBERT_Mask 3.92545976260561e-05\n",
      "Univariant-DistilBERT_Partition 1.392926005087918e-08\n",
      "Univariant-Roberta_Mask 0.0953394711819031\n",
      "Univariant-Roberta_Partition 2.1298180254071483e-07\n",
      "SVM_STI-FFN_STI 0.0005167953282108668\n",
      "SVM_STI-LSTM 1.6638477015826274e-08\n",
      "SVM_STI-DistilBERT_Mask 0.0019292380540899526\n",
      "SVM_STI-DistilBERT_Partition 0.0004364397570627444\n",
      "SVM_STI-Roberta_Mask 2.3804054361022537e-07\n",
      "SVM_STI-Roberta_Partition 0.0016303539808534212\n",
      "FFN_STI-LSTM 7.310109960582633e-05\n",
      "FFN_STI-DistilBERT_Mask 0.3752967018003812\n",
      "FFN_STI-DistilBERT_Partition 0.17340104854870136\n",
      "FFN_STI-Roberta_Mask 0.005082435924973718\n",
      "FFN_STI-Roberta_Partition 0.6016020352598712\n",
      "LSTM-DistilBERT_Mask 0.0004143164587750033\n",
      "LSTM-DistilBERT_Partition 0.005843083229105679\n",
      "LSTM-Roberta_Mask 0.26961991193950147\n",
      "LSTM-Roberta_Partition 0.0002204388435708988\n",
      "DistilBERT_Mask-DistilBERT_Partition 0.3109100189624253\n",
      "DistilBERT_Mask-Roberta_Mask 1.7693990891723516e-05\n",
      "DistilBERT_Mask-Roberta_Partition 0.469902427643068\n",
      "DistilBERT_Partition-Roberta_Mask 0.018667150226197676\n",
      "DistilBERT_Partition-Roberta_Partition 0.06727751967588498\n",
      "Roberta_Mask-Roberta_Partition 5.451843754455381e-05\n"
     ]
    }
   ],
   "source": [
    "p = {}\n",
    "results_indomain = results[results.Within==True]\n",
    "results_across = results[results.Within==False]\n",
    "for i in range(len(methods)):\n",
    "    for j in range(i+1, len(methods)):\n",
    "        pair = methods[i]+'-'+methods[j]\n",
    "        if pair not in p:\n",
    "            p[pair] = []\n",
    "        data1_indomain = results_indomain[results_indomain[\"Method\"]==methods[i]]\n",
    "        data2_indomain = results_indomain[results_indomain[\"Method\"]==methods[j]]\n",
    "        data_indomain = data1_indomain.merge(data2_indomain, on=[\"TrainData\", \"TestData\"])\n",
    "        data1_across = results_across[results_across[\"Method\"]==methods[i]]\n",
    "        data2_across = results_across[results_across[\"Method\"]==methods[j]]\n",
    "        data_across = data1_across.merge(data2_across, on=[\"TrainData\", \"TestData\"])\n",
    "        for k in [\"modelF1\", \"lexiconF1\"]:\n",
    "            p[pair].append(stats.ttest_rel(data_indomain[k+\"_x\"],data_indomain[k+\"_y\"]).pvalue)\n",
    "            p[pair].append(stats.ttest_rel(data_across[k+\"_x\"],data_across[k+\"_y\"]).pvalue)\n",
    "for i in range(4):\n",
    "    for k in p:\n",
    "        print(k, p[k][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "civic-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_indomain = results_indomain[results_indomain[\"Method\"]==methods[1]]\n",
    "data2_indomain = results_indomain[results_indomain[\"Method\"]==methods[0]]\n",
    "data_indomain = data1_indomain.merge(data2_indomain, on=[\"TrainData\", \"TestData\"])\n",
    "data1_across = results_across[results_across[\"Method\"]==methods[i]]\n",
    "data2_across = results_across[results_across[\"Method\"]==methods[j]]\n",
    "data_across = data1_across.merge(data2_across, on=[\"TrainData\", \"TestData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "mysterious-direction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-5.0960939698068195, pvalue=0.0014056024196088027)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_rel(data_indomain[\"lexiconF1_y\"],data_indomain[\"lexiconF1_x\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-family",
   "metadata": {},
   "source": [
    "#### Lexicon Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "preceding-maple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariant FFN\n",
      "0.2964588428418767\n",
      "Univariant SVM\n",
      "0.27284928014890564\n",
      "Univariant LSTM\n",
      "0.4525486486366554\n",
      "Univariant Roberta_Mask\n",
      "0.11574380832305828\n",
      "Univariant Roberta_Partition\n",
      "0.37027570925966613\n",
      "Univariant DistilBERT_Mask\n",
      "0.12660129861542443\n",
      "Univariant DistilBERT_Partition\n",
      "0.42421546731012194\n",
      "FFN SVM\n",
      "0.8770304803664702\n",
      "FFN LSTM\n",
      "0.2692479381963058\n",
      "FFN Roberta_Mask\n",
      "0.1704436100420134\n",
      "FFN Roberta_Partition\n",
      "0.23436658323758802\n",
      "FFN DistilBERT_Mask\n",
      "0.20710077091659487\n",
      "FFN DistilBERT_Partition\n",
      "0.20705238352376343\n",
      "SVM LSTM\n",
      "0.2631514467765863\n",
      "SVM Roberta_Mask\n",
      "0.176272999999214\n",
      "SVM Roberta_Partition\n",
      "0.23693712833351757\n",
      "SVM DistilBERT_Mask\n",
      "0.21603801238850442\n",
      "SVM DistilBERT_Partition\n",
      "0.20853987909078398\n",
      "LSTM Roberta_Mask\n",
      "0.15178916665675568\n",
      "LSTM Roberta_Partition\n",
      "0.2932418469564974\n",
      "LSTM DistilBERT_Mask\n",
      "0.17615897993008464\n",
      "LSTM DistilBERT_Partition\n",
      "0.2807025686242472\n",
      "Roberta_Mask Roberta_Partition\n",
      "0.3297848867341212\n",
      "Roberta_Mask DistilBERT_Mask\n",
      "0.3191512742015382\n",
      "Roberta_Mask DistilBERT_Partition\n",
      "0.11391676466041714\n",
      "Roberta_Partition DistilBERT_Mask\n",
      "0.24201120529504938\n",
      "Roberta_Partition DistilBERT_Partition\n",
      "0.6254704910564381\n",
      "DistilBERT_Mask DistilBERT_Partition\n",
      "0.21808315199188671\n"
     ]
    }
   ],
   "source": [
    "methods = {          \n",
    "           'Univariant': 'uni',\n",
    "           'FFN': 'ffn_feature',\n",
    "           'SVM': 'svm_feature',\n",
    "           'LSTM': 'lstm_attention',\n",
    "           'Roberta_Mask': 'roberta_classification_mask', \n",
    "           'Roberta_Partition': 'roberta_classification_ps',\n",
    "           'DistilBERT_Mask': 'distilbert_classification_mask',\n",
    "           'DistilBERT_Partition': 'distilbert_classification_ps',\n",
    "          }\n",
    "methods_list = list(methods.keys())\n",
    "datalist = ['amazon_finefood_subset', 'amazon_toys_subset', 'yelp_subset'] + ['nrc_'+i for i in ['surprise', 'joy', 'anger', 'sadness', 'fear']]\n",
    "\n",
    "for i in range(len(methods_list)):\n",
    "    for j in range(i+1, len(methods_list)):\n",
    "        print(methods_list[i], methods_list[j])\n",
    "        score = 0\n",
    "        for data in datalist:\n",
    "            lexica_1 = pd.read_csv('../lexica/'+methods_list[i]+'/'+data+'_'+methods[methods_list[i]]+'.csv')\n",
    "            lexica_2 = pd.read_csv('../lexica/'+methods_list[j]+'/'+data+'_'+methods[methods_list[j]]+'.csv')\n",
    "            for k in [lexica_1, lexica_2]:\n",
    "                if 'word' in k.columns:\n",
    "                    k.columns = ['Word', 'Value', 'Freq']\n",
    "            lexica = lexica_1.merge(lexica_2, on=['Word'], how='inner')\n",
    "            score += stats.pearsonr(lexica['Value_x'], lexica['Value_y'])[0]\n",
    "        print(score/8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rating]",
   "language": "python",
   "name": "conda-env-rating-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
