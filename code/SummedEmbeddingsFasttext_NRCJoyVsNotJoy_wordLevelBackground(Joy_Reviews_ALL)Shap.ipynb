{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wr6fHCNvf3ol"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import io\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "IRI_-_R4gC0J",
    "outputId": "41d6d77f-f65e-4d11-f671-9fa114f46b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(All_Reviews)Shap.ipynb\r\n",
      "MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy_Reviews_ALL)Shap.ipynb\r\n",
      "MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy_Reviews)Shap.ipynb\r\n",
      "MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Non_Joy_Reviews_ALL)Shap.ipynb\r\n",
      "MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Non_Joy_Reviews)Shap.ipynb\r\n",
      "SummedEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(All_Reviews)Shap.ipynb\r\n",
      "SummedEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy_Reviews_ALL)Shap.ipynb\r\n",
      "SummedEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy_Reviews)Shap.ipynb\r\n",
      "SummedEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Non_Joy_Reviews)Shap.ipynb\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjss/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "%ls\n",
    "prefix = '/data1/tjss/'\n",
    "# prefix = '/content/drive/My Drive/Summer research /'\n",
    "doc_level_df = pd.read_csv(prefix+'data/msgs_tec.csv')\n",
    "word_level_df = pd.read_csv(prefix+'data/NRC_ht_emotion_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "oiDWuOZLgNEj",
    "outputId": "7c7cb984-fdd7-4b1e-8ae0-54ba110b3aa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21051, 3)\n",
      "['surprise' 'sadness' 'joy' 'disgust' 'fear' 'anger' nan]\n",
      "(21049, 3)\n",
      "           message_id                                            message  \\\n",
      "0  145353048817012736  thinks that @melbahughes had a great 50th birt...   \n",
      "1  144279638024257536  como una expresi達続n tan simple, una sola oraci...   \n",
      "2  140499585285111809  the moment when you get another follower and y...   \n",
      "3  145207578270507009  be the greatest dancer of your life! practice ...   \n",
      "4  139502146390470656  eww.. my moms starting to make her annual rum ...   \n",
      "5  146042696899887106  if ur heart hurts all the time for tht person ...   \n",
      "6  145492569609084928  i feel awful, and it's way too freaking early....   \n",
      "7  145903955229151232  so chuffed for safc fans! bet me dar comes in ...   \n",
      "8  142717613234069504  making art and viewing art are different at th...   \n",
      "9  144183822873927680  soooo dooowwwn!! move on, get some sleep... me...   \n",
      "\n",
      "    emotion  emotion_code  \n",
      "0  surprise             5  \n",
      "1   sadness             4  \n",
      "2       joy             3  \n",
      "3       joy             3  \n",
      "4   disgust             1  \n",
      "5       joy             3  \n",
      "6       joy             3  \n",
      "7       joy             3  \n",
      "8      fear             2  \n",
      "9     anger             0  \n",
      "                                             message  emotion_code\n",
      "0  thinks that @melbahughes had a great 50th birt...             5\n",
      "1  como una expresi達続n tan simple, una sola oraci...             4\n",
      "2  the moment when you get another follower and y...             3\n",
      "3  be the greatest dancer of your life! practice ...             3\n",
      "4  eww.. my moms starting to make her annual rum ...             1\n",
      "5  if ur heart hurts all the time for tht person ...             3\n",
      "6  i feel awful, and it's way too freaking early....             3\n",
      "7  so chuffed for safc fans! bet me dar comes in ...             3\n",
      "8  making art and viewing art are different at th...             2\n",
      "9  soooo dooowwwn!! move on, get some sleep... me...             0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjss/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "print(doc_level_df.shape)\n",
    "print(doc_level_df.emotion.unique())\n",
    "doc_level_df = doc_level_df.dropna()\n",
    "print(doc_level_df.shape)\n",
    "doc_level_df['message'] = doc_level_df['message'].str.lower() \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "doc_level_df['emotion_code'] = lb_make.fit_transform(doc_level_df['emotion'])\n",
    "print(doc_level_df.iloc[:10,:])\n",
    "new_doc_level_df = doc_level_df[['message', 'emotion_code']]\n",
    "print(new_doc_level_df.iloc[:10,:])\n",
    "new_doc_level_df.head(10)\n",
    "\n",
    "new_doc_level_df.loc[(new_doc_level_df.emotion_code!=3),'emotion_code']=0\n",
    "new_doc_level_df.loc[(new_doc_level_df.emotion_code==3),'emotion_code']=1\n",
    "\n",
    "new_doc_level_train, new_doc_level_test = train_test_split(new_doc_level_df, test_size=0.2, random_state=1)\n",
    "new_doc_level_train, new_doc_level_val = train_test_split(new_doc_level_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "sjxuEF8YYDeb",
    "outputId": "40f010c9-a225-4358-fc8e-60f07accd8f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7706\n",
      "1    4923\n",
      "Name: emotion_code, dtype: int64\n",
      "0    2570\n",
      "1    1640\n",
      "Name: emotion_code, dtype: int64\n",
      "0    2534\n",
      "1    1676\n",
      "Name: emotion_code, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_doc_level_train.emotion_code.value_counts())\n",
    "print(new_doc_level_val.emotion_code.value_counts())\n",
    "print(new_doc_level_test.emotion_code.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "y6hLTPzco8WC",
    "outputId": "2cb701ba-8fba-40a3-ef67-4a72d0a6d776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12629, 2)\n",
      "(4210, 2)\n",
      "(4210, 2)\n"
     ]
    }
   ],
   "source": [
    "print(new_doc_level_train.shape)\n",
    "print(new_doc_level_val.shape)\n",
    "print(new_doc_level_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Fo05evYnQUp"
   },
   "outputs": [],
   "source": [
    "# 0-> not Joy\n",
    "# 1-> Joy\n",
    "\n",
    "\n",
    "# 0 Anger\n",
    "# 1 Disgust\n",
    "# 2 Fear\n",
    "# 3 Joy\n",
    "# 4 Sadness\n",
    "# 5 Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xl1BG8qjgz80"
   },
   "outputs": [],
   "source": [
    "new_doc_level_train.to_csv(prefix+\"data/new_doc_level_train.csv\")\n",
    "new_doc_level_val.to_csv(prefix+\"data/new_doc_level_val.csv\")\n",
    "new_doc_level_test.to_csv(prefix+\"data/new_doc_level_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_XwO75pfkNJ"
   },
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2sq_wE0flnS"
   },
   "outputs": [],
   "source": [
    "embeddings = load_vectors(prefix+\"data/crawl-300d-2M.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "7O1khsu9b4Nd",
    "outputId": "31dda153-f91f-47b8-93b7-c3633bbba8ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "1999995\n"
     ]
    }
   ],
   "source": [
    "print(type(embeddings))\n",
    "print(len(embeddings))\n",
    "for word in embeddings:\n",
    "  embeddings[word] = [float(i) for i in embeddings[word]]\n",
    "embeddings_keylist = list(embeddings)\n",
    "embeddings_vectorlist = list(embeddings.values())\n",
    "word_to_index={}\n",
    "index_to_word={}\n",
    "for i in range(len(embeddings_keylist)):\n",
    "  word_to_index[embeddings_keylist[i]]=i\n",
    "  index_to_word[i]=embeddings_keylist[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "tE0UZdh5__8l",
    "outputId": "7dc514d3-244a-49c3-a507-c8af342d3cc8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tjss/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# from spacy.lang.en import English\n",
    "# nlp = English()\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "# tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EuLbh7GHJ4f9"
   },
   "outputs": [],
   "source": [
    "# # Dummy dataloader\n",
    "# test_df = pd.read_csv(prefix+\"data/new_doc_level_val.csv\")\n",
    "# print(test_df.shape)\n",
    "# test_df = test_df.iloc[:,1:]\n",
    "# curr_tex = test_df.iloc[6,0]\n",
    "# curr_emot = test_df.iloc[6,1]\n",
    "# curr_embed = np.zeros((300))\n",
    "# print(\"curr text\", curr_tex)\n",
    "# print(curr_embed)\n",
    "# tot_cnt=0\n",
    "# ign_cnt=0\n",
    "# for word in word_tokenize(curr_tex):\n",
    "#   print(word)\n",
    "#   tot_cnt+=1\n",
    "#   if word in embeddings.keys():\n",
    "#     curr_embed = curr_embed+embeddings[word]\n",
    "#   else:\n",
    "#     ign_cnt+=1\n",
    "# print(\"percentage lost\", ign_cnt/tot_cnt*100, \"%\")\n",
    "# print(curr_embed.shape)\n",
    "# curr_embed = curr_embed\n",
    "# embed_t = torch.from_numpy(curr_embed)\n",
    "# print(embed_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X38r6yCXc3WW"
   },
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRYOx4w7l5Un"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4BDQQe_ylDf"
   },
   "outputs": [],
   "source": [
    "class FastTextVectorLoader(Dataset):\n",
    "  def __init__(self, csv_file, embeddings):\n",
    "    self.frame = pd.read_csv(csv_file)\n",
    "    self.embeddings = embeddings\n",
    "  def __len__(self):\n",
    "    return len(self.frame)\n",
    "  def __getitem__(self, idx):\n",
    "    if torch.is_tensor(idx):\n",
    "      idx = idx.tolist()\n",
    "    curr_tex = self.frame.iloc[idx,1]\n",
    "    curr_emot = self.frame.iloc[idx,2]\n",
    "    curr_embed = np.zeros((300))\n",
    "    tot_cnt=0\n",
    "    ign_cnt=0\n",
    "    \n",
    "    for word in word_tokenize(curr_tex):\n",
    "      tot_cnt+=1\n",
    "      if word in embeddings.keys():\n",
    "        # print(word)\n",
    "        curr_embed = curr_embed+embeddings[word]\n",
    "      else:\n",
    "        ign_cnt+=1\n",
    "    # print(\"percentage lost\", ign_cnt/tot_cnt*100, \"%\")\n",
    "    curr_embed = curr_embed\n",
    "    embed_t = torch.from_numpy(curr_embed)\n",
    "    # embed_t = embed_t.to(torch.device(\"cuda:0\"))\n",
    "    # curr_emot = curr_emot.cuda()\n",
    "    data = {'vector':embed_t, 'label':curr_emot}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_FG_WCG_RJ06"
   },
   "outputs": [],
   "source": [
    "train_dataset = FastTextVectorLoader(prefix+\"data/new_doc_level_train.csv\", embeddings)\n",
    "val_dataset = FastTextVectorLoader(prefix+\"data/new_doc_level_val.csv\", embeddings)\n",
    "test_dataset = FastTextVectorLoader(prefix+\"data/new_doc_level_test.csv\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdXJ4Rj1Z-j_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKAZyx0aQhJ9"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64,shuffle=True, num_workers=1)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64,shuffle=True, num_workers=1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "kRNxH_61jshw",
    "outputId": "2e7f4ddd-2785-456d-9d4b-757e0b52ca09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5257, -1.0272,  0.8305,  ...,  0.1783, -3.0080, -0.5485],\n",
      "        [-1.3625,  0.2093, -0.3486,  ..., -0.1467, -0.1164,  0.8889],\n",
      "        [-0.7734, -0.5827,  0.2372,  ..., -0.1599, -0.3608, -1.4635],\n",
      "        ...,\n",
      "        [-1.7623, -1.0146, -0.3923,  ..., -1.6620,  0.2653, -0.8357],\n",
      "        [-0.5866, -1.7121,  0.1568,  ...,  0.0926, -0.8254, -0.1853],\n",
      "        [-1.5900, -1.9276, -0.4567,  ..., -0.4583, -0.3000,  0.1268]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([64, 300])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0])\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# testing dataloader\n",
    "count = 0\n",
    "for i,batch_data in enumerate(train_dataloader):\n",
    "  count += 1\n",
    "  print(batch_data['vector'])\n",
    "  print(batch_data['vector'].size())\n",
    "  print(batch_data['label'])\n",
    "  # batch_data['vector'].cuda()\n",
    "  # batch_data['vector'].to(device)\n",
    "  print(batch_data['vector'].is_cuda)\n",
    "  print(batch_data['label'].is_cuda)\n",
    "  # print(text)\n",
    "  # print(text_length)\n",
    "  if count == 1:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eU6mIWE3kTv3"
   },
   "outputs": [],
   "source": [
    " def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text_vector = batch['vector']\n",
    "        # text_vector = batch['vector'].to(device)\n",
    "        predictions = model(text_vector)\n",
    "        \n",
    "        y_pred_tag = torch.round(torch.sigmoid(predictions))\n",
    "        \n",
    "        # labels = batch['label'].to(device)\n",
    "        labels = batch['label']\n",
    "        labels = labels.float()\n",
    "        labels = labels.reshape([ len(labels),1])\n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        f1 = f1_score(labels.detach().numpy(), y_pred_tag.detach().numpy())\n",
    "        acc = calc_accuracy(y_pred_tag, labels)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47W1DHtdksOV"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text_vector = batch['vector']\n",
    "            # text_vector = batch['vector'].to(device)\n",
    "            predictions = model(text_vector)\n",
    "            y_pred_tag = torch.round(torch.sigmoid(predictions))\n",
    "            labels = batch['label']\n",
    "            # labels = batch['label'].to(device)\n",
    "            labels = labels.float()\n",
    "            labels = labels.reshape([len(labels),1])\n",
    "            loss = criterion(predictions, labels)\n",
    "            f1 = f1_score(labels, y_pred_tag)\n",
    "            acc = calc_accuracy(y_pred_tag, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udGjp8J9pVdU"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbZMYhOnr7dM"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    # rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    \n",
    "    correct = (preds == y).float() #convert into float for division \n",
    "    # print(correct)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFe5LtebkyQM"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, embedding_length, output_dim):        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_length = embedding_length\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # self.embedding = nn.Embedding(self.vocab_size, self.embedding_length, padding_idx=pad_idx)\n",
    "        # self.embedding.weight = nn.Parameter(word_embeddings, requires_grad = False)\n",
    "        self.fc1 = nn.Linear(self.embedding_length, 512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,128)\n",
    "        self.fc4 = nn.Linear(128, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.dropout2 = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self, text):        \n",
    "        pooled_drop_op = self.dropout1(text)\n",
    "        fc1_op = self.fc1(pooled_drop_op)\n",
    "        fc1_drop_op = self.dropout2(fc1_op)\n",
    "        fc2_op = self.fc2(fc1_drop_op)\n",
    "        fc2_drop_op = self.dropout2(fc2_op) \n",
    "        fc3_op = self.fc3(fc2_drop_op)       \n",
    "        return self.fc4(fc3_op)\n",
    "        # text = self.relu(self.fc1(text))\n",
    "        # text = self.relu(self.fc2(text))\n",
    "        # text = self.relu(self.fc3(text))\n",
    "        # text = self.dropout1(text)\n",
    "        # return self.fc4(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHQVdgr8oPO5"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "OUTPUT_DIM = 1\n",
    "model = FastText( EMBEDDING_DIM,OUTPUT_DIM)\n",
    "model = model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QoK6Fnd9pAwc"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "EgdDPofYpZPs",
    "outputId": "3234c467-71a0-4be9-8276-150d11954c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.661 | Train Acc: 60.23% | Train F1:0.5333333333333333\n",
      "\t Val. Loss: 0.637 |  Val. Acc: 63.65% | Val F1:0.0909090909090909\n",
      "Epoch: 02 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.627 | Train Acc: 65.87% | Train F1:0.46153846153846156\n",
      "\t Val. Loss: 0.613 |  Val. Acc: 68.44% | Val F1:0.48275862068965514\n",
      "Epoch: 03 | Epoch Time: 0m 14s\n",
      "\tTrain Loss: 0.605 | Train Acc: 69.26% | Train F1:0.6666666666666666\n",
      "\t Val. Loss: 0.595 |  Val. Acc: 70.19% | Val F1:0.5714285714285715\n",
      "Epoch: 04 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.591 | Train Acc: 70.15% | Train F1:0.5882352941176471\n",
      "\t Val. Loss: 0.580 |  Val. Acc: 71.77% | Val F1:0.4242424242424242\n",
      "Epoch: 05 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.577 | Train Acc: 71.43% | Train F1:0.5000000000000001\n",
      "\t Val. Loss: 0.568 |  Val. Acc: 72.31% | Val F1:0.5806451612903225\n",
      "Epoch: 06 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.563 | Train Acc: 72.55% | Train F1:0.5714285714285714\n",
      "\t Val. Loss: 0.558 |  Val. Acc: 72.92% | Val F1:0.6666666666666667\n",
      "Epoch: 07 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.558 | Train Acc: 72.64% | Train F1:0.30769230769230765\n",
      "\t Val. Loss: 0.551 |  Val. Acc: 73.05% | Val F1:0.5416666666666666\n",
      "Epoch: 08 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.547 | Train Acc: 73.76% | Train F1:0.22222222222222224\n",
      "\t Val. Loss: 0.544 |  Val. Acc: 73.44% | Val F1:0.6451612903225806\n",
      "Epoch: 09 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.542 | Train Acc: 74.03% | Train F1:0.4615384615384615\n",
      "\t Val. Loss: 0.541 |  Val. Acc: 73.95% | Val F1:0.2962962962962963\n",
      "Epoch: 10 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.539 | Train Acc: 74.06% | Train F1:0.7777777777777778\n",
      "\t Val. Loss: 0.535 |  Val. Acc: 74.02% | Val F1:0.5714285714285714\n",
      "Epoch: 11 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.535 | Train Acc: 74.32% | Train F1:0.7272727272727272\n",
      "\t Val. Loss: 0.533 |  Val. Acc: 74.80% | Val F1:0.7567567567567567\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS =11\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc, train_f1 = train(model, train_dataloader, optimizer, criterion)\n",
    "    valid_loss, valid_acc, val_f1 = evaluate(model, val_dataloader, criterion)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1:{train_f1}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Val F1:{val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "0QgAPZ9VpfE9",
    "outputId": "c25329dc-df87-48af-e250-93b4ad7e141d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.522 | Test Acc: 75.73% | Test F1: 0.5161290322580646\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss, test_acc, test_f1 = evaluate(model, test_dataloader, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1: {test_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HgzaTXwcEjqO"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),prefix+'data/SummedEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy Reviews_All)Shap.pt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "V3tB0RxnFSjZ",
    "outputId": "1885a45d-ae23-4444-ffcf-b0deb73f095a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastText(\n",
       "  (fc1): Linear(in_features=300, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = FastText(EMBEDDING_DIM,OUTPUT_DIM)\n",
    "model1.load_state_dict(torch.load(prefix+'data/SummedEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy Reviews_All)Shap.pt'))\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "UZPMKoEHRqXy",
    "outputId": "e62659ad-f410-4d79-b416-7f5837b3f416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /home/tjss/miniconda3/lib/python3.7/site-packages (0.35.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /home/tjss/miniconda3/lib/python3.7/site-packages (from shap) (4.47.0)\n",
      "Requirement already satisfied: scipy in /home/tjss/miniconda3/lib/python3.7/site-packages (from shap) (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/tjss/miniconda3/lib/python3.7/site-packages (from shap) (1.19.1)\n",
      "Requirement already satisfied: scikit-learn in /home/tjss/miniconda3/lib/python3.7/site-packages (from shap) (0.23.1)\n",
      "Requirement already satisfied: pandas in /home/tjss/miniconda3/lib/python3.7/site-packages (from shap) (1.0.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tjss/miniconda3/lib/python3.7/site-packages (from scikit-learn->shap) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/tjss/miniconda3/lib/python3.7/site-packages (from scikit-learn->shap) (0.16.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/tjss/miniconda3/lib/python3.7/site-packages (from pandas->shap) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/tjss/miniconda3/lib/python3.7/site-packages (from pandas->shap) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/tjss/miniconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->shap) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install shap\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "TntpaHO0UdBL",
    "outputId": "560d958b-43bc-4eed-f655-47b27ca61ea6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>message</th>\n",
       "      <th>emotion_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11390</td>\n",
       "      <td>io domani volevo vestirmi tutta figa, ma il mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1136</td>\n",
       "      <td>churchhhh! then exam stuff, and making 30 dang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9805</td>\n",
       "      <td>empty fuel tank &amp; a $ load of traffic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16383</td>\n",
       "      <td>he who cannot forgive others destroys the brid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12353</td>\n",
       "      <td>hoje meu dia vai ser study study and study. te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            message  emotion_code\n",
       "0       11390  io domani volevo vestirmi tutta figa, ma il mi...             0\n",
       "1        1136  churchhhh! then exam stuff, and making 30 dang...             1\n",
       "2        9805              empty fuel tank & a $ load of traffic             1\n",
       "3       16383  he who cannot forgive others destroys the brid...             1\n",
       "4       12353  hoje meu dia vai ser study study and study. te...             0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(prefix+\"data/new_doc_level_train.csv\")\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfDcuDv3m76N"
   },
   "outputs": [],
   "source": [
    "def get_word_embeddings(dataframe_csv):\n",
    "  vocab={}\n",
    "  bg = torch.empty((0,300))\n",
    "  df = pd.read_csv(dataframe_csv)\n",
    "  for idx, row in df.iterrows():\n",
    "    curr_text = df.iloc[idx,1]\n",
    "    curr_label = df.iloc[idx,2]\n",
    "    if(curr_label==1):\n",
    "      for word in word_tokenize(curr_text):\n",
    "        if(word in embeddings.keys() and word not in vocab.keys()):\n",
    "          vocab[word]=0\n",
    "          curr_embed = torch.from_numpy(np.array(embeddings[word]))\n",
    "          curr_embed = curr_embed.reshape((1, len(curr_embed)))\n",
    "          bg = torch.cat((bg, curr_embed))\n",
    "#     if(idx==idx_limit):\n",
    "#       break\n",
    "\n",
    "  return bg, vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "ANtCW16Rp-CR",
    "outputId": "cd1d01e0-1749-40b2-80d0-085c798b55f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8458, 300])\n"
     ]
    }
   ],
   "source": [
    "new_bg,_ = get_word_embeddings(prefix+\"data/new_doc_level_train.csv\")\n",
    "print(new_bg.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EspAw9YDR1J0"
   },
   "outputs": [],
   "source": [
    "e = shap.DeepExplainer(model, new_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "MPZxW1g7CRCR",
    "outputId": "835abaf9-e01d-401c-c0c6-8bd32d152e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4520, 300])\n"
     ]
    }
   ],
   "source": [
    "explain_examples, vocab1  = get_word_embeddings(prefix+\"data/new_doc_level_test.csv\")\n",
    "print(explain_examples.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "n5ChYAiwR-ii",
    "outputId": "9c2547d4-b144-4100-d606-831476de4e7b"
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "shap_vals = e.shap_values(explain_examples.float())\n",
    "print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "1YiRb7nyuUqX",
    "outputId": "23cccc8a-ce84-448e-b440-e637fcbd897a"
   },
   "outputs": [],
   "source": [
    "print(len(shap_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "e31RHDakUnU4",
    "outputId": "74ba4a05-8ef4-403e-baa5-9808e3382816"
   },
   "outputs": [],
   "source": [
    "print(len(vocab1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "G-7SHXIWYfG3",
    "outputId": "4e7e182f-89a7-4d40-c175-e7d25c8243fb"
   },
   "outputs": [],
   "source": [
    "\n",
    "print((shap_vals).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnWlK8ENYqQ2"
   },
   "outputs": [],
   "source": [
    "shap_means_joy = shap_vals.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TG35Zc8RphVp"
   },
   "outputs": [],
   "source": [
    "idx=0\n",
    "for word in vocab1:\n",
    "  vocab1[word]=shap_means_joy[idx]\n",
    "  idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "40r0qaFpc7V1",
    "outputId": "fd2291de-a4b9-4717-f4f0-829a63e9c15f"
   },
   "outputs": [],
   "source": [
    "for word in vocab1:\n",
    "  print(word, \" \", vocab1[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQxxKUSEcu-G"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(vocab1.items()),columns = ['column1','column2']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1GJ3vEadlvI"
   },
   "outputs": [],
   "source": [
    "lexicon_df_joy = df.sort_values(by='column2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "gPveYiT2cZ3C",
    "outputId": "78fee39b-dfef-41a4-86e9-2331b5e32b1c"
   },
   "outputs": [],
   "source": [
    "lexicon_df_joy.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "_sC40J82dvLP",
    "outputId": "3a1efda7-8ad4-4e38-8f05-d4c2a477ca9f"
   },
   "outputs": [],
   "source": [
    "lexicon_df_joy.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ThC43hKww7i"
   },
   "outputs": [],
   "source": [
    "lexicon_df_joy.to_csv(prefix+\"results/SummedEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy Reviews_ALL)Shap.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HC7jPS-nkIry"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SummedEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy Reviews)Shap.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
