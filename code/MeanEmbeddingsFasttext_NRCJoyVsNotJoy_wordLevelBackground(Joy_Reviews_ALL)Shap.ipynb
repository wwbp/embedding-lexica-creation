{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wr6fHCNvf3ol"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import io\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "IRI_-_R4gC0J",
    "outputId": "b31213fb-4d03-4036-d7ad-165daf3af57c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(All_Reviews)Shap.ipynb\r\n",
      "MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy_Reviews_ALL)Shap.ipynb\r\n",
      "MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy_Reviews)Shap.ipynb\r\n",
      "MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Non_Joy_Reviews_ALL)Shap.ipynb\r\n",
      "MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Non_Joy_Reviews)Shap.ipynb\r\n",
      "SummedEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(All_Reviews)Shap.ipynb\r\n",
      "SummedEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy_Reviews)Shap.ipynb\r\n",
      "SummedEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Non_Joy_Reviews)Shap.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "%ls\n",
    "prefix = '/data1/tjss/'\n",
    "# prefix = '/content/drive/My Drive/Summer research /'\n",
    "doc_level_df = pd.read_csv(prefix+'data/msgs_tec.csv')\n",
    "word_level_df = pd.read_csv(prefix+'data/NRC_ht_emotion_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "colab_type": "code",
    "id": "oiDWuOZLgNEj",
    "outputId": "47773f81-3e80-4835-8e8a-03dc75382b8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21051, 3)\n",
      "['surprise' 'sadness' 'joy' 'disgust' 'fear' 'anger' nan]\n",
      "(21049, 3)\n",
      "           message_id                                            message  \\\n",
      "0  145353048817012736  thinks that @melbahughes had a great 50th birt...   \n",
      "1  144279638024257536  como una expresi達続n tan simple, una sola oraci...   \n",
      "2  140499585285111809  the moment when you get another follower and y...   \n",
      "3  145207578270507009  be the greatest dancer of your life! practice ...   \n",
      "4  139502146390470656  eww.. my moms starting to make her annual rum ...   \n",
      "5  146042696899887106  if ur heart hurts all the time for tht person ...   \n",
      "6  145492569609084928  i feel awful, and it's way too freaking early....   \n",
      "7  145903955229151232  so chuffed for safc fans! bet me dar comes in ...   \n",
      "8  142717613234069504  making art and viewing art are different at th...   \n",
      "9  144183822873927680  soooo dooowwwn!! move on, get some sleep... me...   \n",
      "\n",
      "    emotion  emotion_code  \n",
      "0  surprise             5  \n",
      "1   sadness             4  \n",
      "2       joy             3  \n",
      "3       joy             3  \n",
      "4   disgust             1  \n",
      "5       joy             3  \n",
      "6       joy             3  \n",
      "7       joy             3  \n",
      "8      fear             2  \n",
      "9     anger             0  \n",
      "                                             message  emotion_code\n",
      "0  thinks that @melbahughes had a great 50th birt...             5\n",
      "1  como una expresi達続n tan simple, una sola oraci...             4\n",
      "2  the moment when you get another follower and y...             3\n",
      "3  be the greatest dancer of your life! practice ...             3\n",
      "4  eww.. my moms starting to make her annual rum ...             1\n",
      "5  if ur heart hurts all the time for tht person ...             3\n",
      "6  i feel awful, and it's way too freaking early....             3\n",
      "7  so chuffed for safc fans! bet me dar comes in ...             3\n",
      "8  making art and viewing art are different at th...             2\n",
      "9  soooo dooowwwn!! move on, get some sleep... me...             0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "print(doc_level_df.shape)\n",
    "print(doc_level_df.emotion.unique())\n",
    "doc_level_df = doc_level_df.dropna()\n",
    "print(doc_level_df.shape)\n",
    "doc_level_df['message'] = doc_level_df['message'].str.lower() \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "doc_level_df['emotion_code'] = lb_make.fit_transform(doc_level_df['emotion'])\n",
    "print(doc_level_df.iloc[:10,:])\n",
    "new_doc_level_df = doc_level_df[['message', 'emotion_code']]\n",
    "print(new_doc_level_df.iloc[:10,:])\n",
    "new_doc_level_df.head(10)\n",
    "\n",
    "new_doc_level_df.loc[(new_doc_level_df.emotion_code!=3),'emotion_code']=0\n",
    "new_doc_level_df.loc[(new_doc_level_df.emotion_code==3),'emotion_code']=1\n",
    "\n",
    "new_doc_level_train, new_doc_level_test = train_test_split(new_doc_level_df, test_size=0.2, random_state=1)\n",
    "new_doc_level_train, new_doc_level_val = train_test_split(new_doc_level_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "sjxuEF8YYDeb",
    "outputId": "aa59c83c-4172-44b9-e89c-4dd7a532ca5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7706\n",
      "1    4923\n",
      "Name: emotion_code, dtype: int64\n",
      "0    2570\n",
      "1    1640\n",
      "Name: emotion_code, dtype: int64\n",
      "0    2534\n",
      "1    1676\n",
      "Name: emotion_code, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_doc_level_train.emotion_code.value_counts())\n",
    "print(new_doc_level_val.emotion_code.value_counts())\n",
    "print(new_doc_level_test.emotion_code.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "y6hLTPzco8WC",
    "outputId": "cba8ae18-c58b-4412-b37e-6b0c32b9d3d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12629, 2)\n",
      "(4210, 2)\n",
      "(4210, 2)\n"
     ]
    }
   ],
   "source": [
    "print(new_doc_level_train.shape)\n",
    "print(new_doc_level_val.shape)\n",
    "print(new_doc_level_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Fo05evYnQUp"
   },
   "outputs": [],
   "source": [
    "# 0-> not Joy\n",
    "# 1-> Joy\n",
    "\n",
    "\n",
    "# 0 Anger\n",
    "# 1 Disgust\n",
    "# 2 Fear\n",
    "# 3 Joy\n",
    "# 4 Sadness\n",
    "# 5 Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xl1BG8qjgz80"
   },
   "outputs": [],
   "source": [
    "new_doc_level_train.to_csv(prefix+\"data/new_doc_level_train.csv\")\n",
    "new_doc_level_val.to_csv(prefix+\"data/new_doc_level_val.csv\")\n",
    "new_doc_level_test.to_csv(prefix+\"data/new_doc_level_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_XwO75pfkNJ"
   },
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2sq_wE0flnS"
   },
   "outputs": [],
   "source": [
    "embeddings = load_vectors(prefix+\"data/crawl-300d-2M.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "7O1khsu9b4Nd",
    "outputId": "4b63c390-55a6-4147-d2ad-fd07b40170a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "1999995\n"
     ]
    }
   ],
   "source": [
    "print(type(embeddings))\n",
    "print(len(embeddings))\n",
    "for word in embeddings:\n",
    "  embeddings[word] = [float(i) for i in embeddings[word]]\n",
    "embeddings_keylist = list(embeddings)\n",
    "embeddings_vectorlist = list(embeddings.values())\n",
    "word_to_index={}\n",
    "index_to_word={}\n",
    "for i in range(len(embeddings_keylist)):\n",
    "  word_to_index[embeddings_keylist[i]]=i\n",
    "  index_to_word[i]=embeddings_keylist[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "tE0UZdh5__8l",
    "outputId": "7a11de4f-80e9-418c-9ce6-bf7511cecd5d"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# from spacy.lang.en import English\n",
    "# nlp = English()\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "# tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EuLbh7GHJ4f9"
   },
   "outputs": [],
   "source": [
    "# # Dummy dataloader\n",
    "# test_df = pd.read_csv(prefix+\"data/new_doc_level_val.csv\")\n",
    "# print(test_df.shape)\n",
    "# test_df = test_df.iloc[:,1:]\n",
    "# curr_tex = test_df.iloc[6,0]\n",
    "# curr_emot = test_df.iloc[6,1]\n",
    "# curr_embed = np.zeros((300))\n",
    "# print(\"curr text\", curr_tex)\n",
    "# print(curr_embed)\n",
    "# tot_cnt=0\n",
    "# ign_cnt=0\n",
    "# for word in word_tokenize(curr_tex):\n",
    "#   print(word)\n",
    "#   tot_cnt+=1\n",
    "#   if word in embeddings.keys():\n",
    "#     curr_embed = curr_embed+embeddings[word]\n",
    "#   else:\n",
    "#     ign_cnt+=1\n",
    "# print(\"percentage lost\", ign_cnt/tot_cnt*100, \"%\")\n",
    "# print(curr_embed.shape)\n",
    "# curr_embed = curr_embed/tot_cnt\n",
    "# embed_t = torch.from_numpy(curr_embed)\n",
    "# print(embed_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X38r6yCXc3WW"
   },
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRYOx4w7l5Un"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4BDQQe_ylDf"
   },
   "outputs": [],
   "source": [
    "class FastTextVectorLoader(Dataset):\n",
    "  def __init__(self, csv_file, embeddings):\n",
    "    self.frame = pd.read_csv(csv_file)\n",
    "    self.embeddings = embeddings\n",
    "  def __len__(self):\n",
    "    return len(self.frame)\n",
    "  def __getitem__(self, idx):\n",
    "    if torch.is_tensor(idx):\n",
    "      idx = idx.tolist()\n",
    "    curr_tex = self.frame.iloc[idx,1]\n",
    "    curr_emot = self.frame.iloc[idx,2]\n",
    "    curr_embed = np.zeros((300))\n",
    "    tot_cnt=0\n",
    "    ign_cnt=0\n",
    "    \n",
    "    for word in word_tokenize(curr_tex):\n",
    "      tot_cnt+=1\n",
    "      if word in embeddings.keys():\n",
    "        # print(word)\n",
    "        curr_embed = curr_embed+embeddings[word]\n",
    "      else:\n",
    "        ign_cnt+=1\n",
    "    # print(\"percentage lost\", ign_cnt/tot_cnt*100, \"%\")\n",
    "    curr_embed = curr_embed/tot_cnt\n",
    "    embed_t = torch.from_numpy(curr_embed)\n",
    "    # embed_t = embed_t.to(torch.device(\"cuda:0\"))\n",
    "    # curr_emot = curr_emot.cuda()\n",
    "    data = {'vector':embed_t, 'label':curr_emot}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_FG_WCG_RJ06"
   },
   "outputs": [],
   "source": [
    "train_dataset = FastTextVectorLoader(prefix+\"data/new_doc_level_train.csv\", embeddings)\n",
    "val_dataset = FastTextVectorLoader(prefix+\"data/new_doc_level_val.csv\", embeddings)\n",
    "test_dataset = FastTextVectorLoader(prefix+\"data/new_doc_level_test.csv\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdXJ4Rj1Z-j_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKAZyx0aQhJ9"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64,shuffle=True, num_workers=1)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64,shuffle=True, num_workers=1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "kRNxH_61jshw",
    "outputId": "ffbccd90-d2b3-4cc4-a6dc-4435e51fbcce"
   },
   "outputs": [],
   "source": [
    "# testing dataloader\n",
    "count = 0\n",
    "for i,batch_data in enumerate(train_dataloader):\n",
    "  count += 1\n",
    "  print(batch_data['vector'])\n",
    "  print(batch_data['vector'].size())\n",
    "  print(batch_data['label'])\n",
    "  # batch_data['vector'].cuda()\n",
    "  # batch_data['vector'].to(device)\n",
    "  print(batch_data['vector'].is_cuda)\n",
    "  print(batch_data['label'].is_cuda)\n",
    "  # print(text)\n",
    "  # print(text_length)\n",
    "  if count == 1:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eU6mIWE3kTv3"
   },
   "outputs": [],
   "source": [
    " def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text_vector = batch['vector']\n",
    "        # text_vector = batch['vector'].to(device)\n",
    "        predictions = model(text_vector)\n",
    "        \n",
    "        y_pred_tag = torch.round(torch.sigmoid(predictions))\n",
    "        \n",
    "        # labels = batch['label'].to(device)\n",
    "        labels = batch['label']\n",
    "        labels = labels.float()\n",
    "        labels = labels.reshape([ len(labels),1])\n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        f1 = f1_score(labels.detach().numpy(), y_pred_tag.detach().numpy())\n",
    "        acc = calc_accuracy(y_pred_tag, labels)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47W1DHtdksOV"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text_vector = batch['vector']\n",
    "            # text_vector = batch['vector'].to(device)\n",
    "            predictions = model(text_vector)\n",
    "            y_pred_tag = torch.round(torch.sigmoid(predictions))\n",
    "            labels = batch['label']\n",
    "            # labels = batch['label'].to(device)\n",
    "            labels = labels.float()\n",
    "            labels = labels.reshape([len(labels),1])\n",
    "            loss = criterion(predictions, labels)\n",
    "            f1 = f1_score(labels, y_pred_tag)\n",
    "            acc = calc_accuracy(y_pred_tag, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udGjp8J9pVdU"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbZMYhOnr7dM"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    # rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    \n",
    "    correct = (preds == y).float() #convert into float for division \n",
    "    # print(correct)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFe5LtebkyQM"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, embedding_length, output_dim):        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_length = embedding_length\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # self.embedding = nn.Embedding(self.vocab_size, self.embedding_length, padding_idx=pad_idx)\n",
    "        # self.embedding.weight = nn.Parameter(word_embeddings, requires_grad = False)\n",
    "        self.fc1 = nn.Linear(self.embedding_length, 512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,128)\n",
    "        self.fc4 = nn.Linear(128, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.dropout2 = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self, text):        \n",
    "        pooled_drop_op = self.dropout1(text)\n",
    "        fc1_op = self.fc1(pooled_drop_op)\n",
    "        fc1_drop_op = self.dropout2(fc1_op)\n",
    "        fc2_op = self.fc2(fc1_drop_op)\n",
    "        fc2_drop_op = self.dropout2(fc2_op) \n",
    "        fc3_op = self.fc3(fc2_drop_op)       \n",
    "        return self.fc4(fc3_op)\n",
    "        # text = self.relu(self.fc1(text))\n",
    "        # text = self.relu(self.fc2(text))\n",
    "        # text = self.relu(self.fc3(text))\n",
    "        # text = self.dropout1(text)\n",
    "        # return self.fc4(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHQVdgr8oPO5"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "OUTPUT_DIM = 1\n",
    "model = FastText( EMBEDDING_DIM,OUTPUT_DIM)\n",
    "model = model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QoK6Fnd9pAwc"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "EgdDPofYpZPs",
    "outputId": "297b535f-da56-4dc3-ced4-c55da62d4752"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS =7\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc, train_f1 = train(model, train_dataloader, optimizer, criterion)\n",
    "    valid_loss, valid_acc, val_f1 = evaluate(model, val_dataloader, criterion)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1:{train_f1}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Val F1:{val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0QgAPZ9VpfE9",
    "outputId": "1a471a73-82d9-4c97-ccd3-b24c535b13f3"
   },
   "outputs": [],
   "source": [
    "# 77% 0.68\n",
    "test_loss, test_acc, test_f1 = evaluate(model, test_dataloader, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1: {test_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HgzaTXwcEjqO"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),prefix+'data/MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy Reviews)Shap.pt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "V3tB0RxnFSjZ",
    "outputId": "d595c8c1-a2ab-4e08-de28-0ae8a55933de"
   },
   "outputs": [],
   "source": [
    "model1 = FastText(EMBEDDING_DIM,OUTPUT_DIM)\n",
    "model1.load_state_dict(torch.load(prefix+'data/MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy Reviews)Shap.pt'))\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "UZPMKoEHRqXy",
    "outputId": "8dc01431-6a19-4c5d-e6f4-e80887e2a6ee"
   },
   "outputs": [],
   "source": [
    "%pip install shap\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "TntpaHO0UdBL",
    "outputId": "824ceba7-4351-4ba8-f696-1d0ba609e514"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(prefix+\"data/new_doc_level_train.csv\")\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfDcuDv3m76N"
   },
   "outputs": [],
   "source": [
    "def get_word_embeddings(dataframe_csv):\n",
    "  vocab={}\n",
    "  bg = torch.empty((0,300))\n",
    "  df = pd.read_csv(dataframe_csv)\n",
    "  for idx, row in df.iterrows():\n",
    "    curr_text = df.iloc[idx,1]\n",
    "    curr_label = df.iloc[idx,2]\n",
    "    if(curr_label==1):\n",
    "      for word in word_tokenize(curr_text):\n",
    "        if(word in embeddings.keys() and word not in vocab.keys()):\n",
    "          vocab[word]=0\n",
    "          curr_embed = torch.from_numpy(np.array(embeddings[word]))\n",
    "          curr_embed = curr_embed.reshape((1, len(curr_embed)))\n",
    "          bg = torch.cat((bg, curr_embed))\n",
    "    \n",
    "\n",
    "  return bg, vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ANtCW16Rp-CR",
    "outputId": "a8645d3d-a198-46c0-a8ac-0e318e192b8e"
   },
   "outputs": [],
   "source": [
    "new_bg,_ = get_word_embeddings(prefix+\"data/new_doc_level_train.csv\", 1500)\n",
    "print(new_bg.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EspAw9YDR1J0"
   },
   "outputs": [],
   "source": [
    "e = shap.DeepExplainer(model, new_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MPZxW1g7CRCR",
    "outputId": "4c753a2e-b1b8-4a92-df45-dea04c0a700a"
   },
   "outputs": [],
   "source": [
    "explain_examples, vocab1  = get_word_embeddings(prefix+\"data/new_doc_level_test.csv\", 1200)\n",
    "print(explain_examples.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n5ChYAiwR-ii",
    "outputId": "afa94193-b8e3-4418-96b6-f6eaad770fec"
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "shap_vals = e.shap_values(explain_examples.float())\n",
    "print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1YiRb7nyuUqX",
    "outputId": "c753d322-1ae3-46a2-acd4-134c1af93c0e"
   },
   "outputs": [],
   "source": [
    "print(len(shap_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e31RHDakUnU4",
    "outputId": "4c69d294-4c7a-44c5-9616-712c43dbe85b"
   },
   "outputs": [],
   "source": [
    "print(len(vocab1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G-7SHXIWYfG3",
    "outputId": "0fde8c38-2a26-4a7c-9025-c41c416686c0"
   },
   "outputs": [],
   "source": [
    "\n",
    "print((shap_vals).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnWlK8ENYqQ2"
   },
   "outputs": [],
   "source": [
    "shap_means_joy = shap_vals.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TG35Zc8RphVp"
   },
   "outputs": [],
   "source": [
    "idx=0\n",
    "for word in vocab1:\n",
    "  vocab1[word]=shap_means_joy[idx]\n",
    "  idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "40r0qaFpc7V1",
    "outputId": "3d911ca0-8a73-41ce-ad20-0d7ba736ba21"
   },
   "outputs": [],
   "source": [
    "for word in vocab1:\n",
    "  print(word, \" \", vocab1[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQxxKUSEcu-G"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(vocab1.items()),columns = ['column1','column2']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1GJ3vEadlvI"
   },
   "outputs": [],
   "source": [
    "lexicon_df_joy = df.sort_values(by='column2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gPveYiT2cZ3C",
    "outputId": "a79bc0e4-7790-4b9c-a091-1029f927b86e"
   },
   "outputs": [],
   "source": [
    "lexicon_df_joy.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_sC40J82dvLP",
    "outputId": "de37c34b-e03e-4d24-88eb-e1d5d4bbb930"
   },
   "outputs": [],
   "source": [
    "lexicon_df_joy.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ThC43hKww7i"
   },
   "outputs": [],
   "source": [
    "lexicon_df_joy.to_csv(prefix+\"results/MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy Reviews_ALL)Shap.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HC7jPS-nkIry"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MeanEmbeddingsFasttext_NRCJoyVsNotJoy_wordLevelBackground(Joy Reviews)Shap.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
