{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a new dataset, only modifying the following shall be sufficient. \n",
    "* Import Data\n",
    "    * directory\n",
    "    * file name\n",
    "    * pd.read_csv() if different file type\n",
    "    * data_name\n",
    "    * label_name\n",
    "* Prepare Data\n",
    "    * In get_train_data function, modify the way binary labels are defined.\n",
    "    * Number of posts (iterations) in get_word_data based on your interest\n",
    "* Results\n",
    "    * Modify the way 'keyword' is used based on your binary labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXWy85hSG3ps"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYi2edrSIhlZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>message</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145353048817012736</td>\n",
       "      <td>Thinks that @melbahughes had a great 50th birt...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144279638024257536</td>\n",
       "      <td>Como una expresiÃ³n tan simple, una sola oraci...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140499585285111809</td>\n",
       "      <td>the moment when you get another follower and y...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145207578270507009</td>\n",
       "      <td>Be the greatest dancer of your life! practice ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139502146390470656</td>\n",
       "      <td>eww.. my moms starting to make her annual rum ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           message_id                                            message  \\\n",
       "0  145353048817012736  Thinks that @melbahughes had a great 50th birt...   \n",
       "1  144279638024257536  Como una expresiÃ³n tan simple, una sola oraci...   \n",
       "2  140499585285111809  the moment when you get another follower and y...   \n",
       "3  145207578270507009  Be the greatest dancer of your life! practice ...   \n",
       "4  139502146390470656  eww.. my moms starting to make her annual rum ...   \n",
       "\n",
       "    emotion  \n",
       "0  surprise  \n",
       "1   sadness  \n",
       "2       joy  \n",
       "3       joy  \n",
       "4   disgust  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/data2/link10/data/nrc/'\n",
    "file_name = 'msgs_tec.csv'\n",
    "raw_df = pd.read_csv(directory + file_name)\n",
    "# remove rows with missing values\n",
    "df = raw_df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'message'\n",
    "label_name = 'emotion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21049 data.\n",
      "Labels are: ['surprise' 'sadness' 'joy' 'disgust' 'fear' 'anger']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "joy         8239\n",
       "surprise    3849\n",
       "sadness     3829\n",
       "fear        2816\n",
       "anger       1555\n",
       "disgust      761\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    'There are {} data.'.format(df.shape[0]),\n",
    "    'Labels are: {}'.format(df[label_name].unique()),\n",
    "    sep = '\\n'\n",
    "    )\n",
    "df[label_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLbPIpy6FBNn"
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "id": "h4H-xS4oRs-M",
    "outputId": "7a860939-7f5a-454b-839d-406aa88fd24d"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBe-lTvJUJ7Y"
   },
   "outputs": [],
   "source": [
    "# # load the language model\n",
    "# nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dCiBEqP8UxPI",
    "outputId": "51aca1ca-5a26-445b-aa83-f079e2348376"
   },
   "outputs": [],
   "source": [
    "# with nlp.disable_pipes():\n",
    "#     msg_vectors = np.array([nlp(msg.lower()).vector for msg in tqdm(df[data_name])])\n",
    "# msg_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nrc_glove_vectors = msg_vectors\n",
    "# %store nrc_glove_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21049, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding takes huge amount of time, use stored result\n",
    "%store -r nrc_glove_vectors\n",
    "msg_vectors = nrc_glove_vectors\n",
    "msg_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='emotion', ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.countplot(x = label_name, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'joy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([1 if x == keyword else 0 for x in df[label_name]])\n",
    "X_train, X_test, y_train, y_test = train_test_split(msg_vectors, labels,\n",
    "                                                    test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardize Input (skip for now)\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ts = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "# Y_train_ts = torch.from_numpy(Y_train).type(torch.LongTensor)\n",
    "# X_test_ts = torch.from_numpy(X_test).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test data\n",
    "class testData(Dataset):    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)#\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer Feed-Forward network with BatchNorm and Dropout\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(300, 1024) \n",
    "        self.layer_2 = nn.Linear(1024, 512)\n",
    "        self.layer_3 = nn.Linear(512, 128)\n",
    "        self.layer_out = nn.Linear(128, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "#         self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "#         self.batchnorm2 = nn.BatchNorm1d(512)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "#         x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "#         x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=300, out_features=1024, bias=True)\n",
      "  (layer_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (layer_3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.55152 | Acc: 72.356\n",
      "Epoch 002: | Loss: 0.49295 | Acc: 76.682\n",
      "Epoch 003: | Loss: 0.47446 | Acc: 78.008\n",
      "Epoch 004: | Loss: 0.44886 | Acc: 79.515\n",
      "Epoch 005: | Loss: 0.43047 | Acc: 80.447\n",
      "Epoch 006: | Loss: 0.40220 | Acc: 81.886\n",
      "Epoch 007: | Loss: 0.37242 | Acc: 83.333\n",
      "Epoch 008: | Loss: 0.34473 | Acc: 84.826\n",
      "Epoch 009: | Loss: 0.31836 | Acc: 86.076\n",
      "Epoch 010: | Loss: 0.29593 | Acc: 87.167\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2017,  517],\n",
       "       [ 442, 1234]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      2534\n",
      "           1       0.70      0.74      0.72      1676\n",
      "\n",
      "    accuracy                           0.77      4210\n",
      "   macro avg       0.76      0.77      0.76      4210\n",
      "weighted avg       0.77      0.77      0.77      4210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_list, word_array, word_occr = get_word_data(nlp,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nrc_glove_word = [word_list, word_array, word_occr]\n",
    "# %store nrc_glove_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stored result\n",
    "%store -r nrc_glove_word\n",
    "word_list = nrc_glove_word[0]\n",
    "word_array = nrc_glove_word[1]\n",
    "word_occr = nrc_glove_word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word data\n",
    "class wordData(Dataset):    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "word_data = wordData(torch.FloatTensor(word_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_loader = DataLoader(dataset=word_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33457/33457 [00:16<00:00, 2013.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "word_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in tqdm(word_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        word_pred = model(X_batch)\n",
    "#         word_pred = torch.sigmoid(word_pred)\n",
    "        word_pred_list.append(word_pred.cpu().numpy())\n",
    "word_pred_list = [a.squeeze().tolist() for a in word_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = pd.DataFrame({'word':word_list,'pred':word_pred_list,'occurrence':word_occr})\n",
    "top_words = top_words.sort_values('pred',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 20\n",
    "pos_words_f = top_words[top_words['occurrence']>thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pred</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>joy</td>\n",
       "      <td>101.101479</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6244</th>\n",
       "      <td>joyful</td>\n",
       "      <td>97.709732</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>blessings</td>\n",
       "      <td>84.334053</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>happiness</td>\n",
       "      <td>73.874496</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>train</td>\n",
       "      <td>69.651146</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>laughter</td>\n",
       "      <td>65.910011</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>essay</td>\n",
       "      <td>64.161926</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143</th>\n",
       "      <td>gratitude</td>\n",
       "      <td>62.377506</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>blessed</td>\n",
       "      <td>60.317436</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>gravy</td>\n",
       "      <td>57.092125</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>cleaning</td>\n",
       "      <td>56.076603</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>spirit</td>\n",
       "      <td>54.984432</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>bus</td>\n",
       "      <td>54.047676</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cheer</td>\n",
       "      <td>52.966843</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>smiles</td>\n",
       "      <td>52.528778</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>tea</td>\n",
       "      <td>51.888432</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>smiling</td>\n",
       "      <td>51.885609</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>cup</td>\n",
       "      <td>50.917072</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>round</td>\n",
       "      <td>48.340717</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>cream</td>\n",
       "      <td>48.064190</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word        pred  occurrence\n",
       "233         joy  101.101479         323\n",
       "6244     joyful   97.709732          25\n",
       "7388  blessings   84.334053          21\n",
       "795   happiness   73.874496         139\n",
       "1549      train   69.651146          59\n",
       "684    laughter   65.910011          24\n",
       "3237      essay   64.161926          69\n",
       "5143  gratitude   62.377506          29\n",
       "5218    blessed   60.317436          46\n",
       "213       gravy   57.092125          26\n",
       "2532   cleaning   56.076603          33\n",
       "3154     spirit   54.984432          67\n",
       "408         bus   54.047676          91\n",
       "31        cheer   52.966843          37\n",
       "3213     smiles   52.528778          23\n",
       "3312        tea   51.888432          38\n",
       "1843    smiling   51.885609          21\n",
       "3311        cup   50.917072          45\n",
       "1709      round   48.340717          33\n",
       "4879      cream   48.064190          33"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joy\n",
    "pos_words_f.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pred</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>fear</td>\n",
       "      <td>-75.341156</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>scared</td>\n",
       "      <td>-71.888382</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>unexpected</td>\n",
       "      <td>-65.836662</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>won</td>\n",
       "      <td>-64.642807</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8161</th>\n",
       "      <td>mo</td>\n",
       "      <td>-63.053478</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025</th>\n",
       "      <td>une</td>\n",
       "      <td>-62.190647</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3664</th>\n",
       "      <td>sur</td>\n",
       "      <td>-60.928333</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>afraid</td>\n",
       "      <td>-60.705723</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>scary</td>\n",
       "      <td>-54.605537</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>ma</td>\n",
       "      <td>-54.097271</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>regret</td>\n",
       "      <td>-53.137775</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>em</td>\n",
       "      <td>-52.654644</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>showed</td>\n",
       "      <td>-52.582260</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>surprise</td>\n",
       "      <td>-52.329491</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>film</td>\n",
       "      <td>-52.246227</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>%</td>\n",
       "      <td>-51.513321</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>miss</td>\n",
       "      <td>-50.996460</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>reality</td>\n",
       "      <td>-50.415108</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>rip</td>\n",
       "      <td>-48.710472</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>fans</td>\n",
       "      <td>-48.475838</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word       pred  occurrence\n",
       "385         fear -75.341156         365\n",
       "696       scared -71.888382         124\n",
       "1340  unexpected -65.836662          21\n",
       "3700         won -64.642807          35\n",
       "8161          mo -63.053478          22\n",
       "5025         une -62.190647          53\n",
       "3664         sur -60.928333          43\n",
       "1503      afraid -60.705723         422\n",
       "2485       scary -54.605537          21\n",
       "1956          ma -54.097271          79\n",
       "945       regret -53.137775          23\n",
       "4683          em -52.654644          39\n",
       "6618      showed -52.582260          21\n",
       "1810    surprise -52.329491         186\n",
       "665         film -52.246227          37\n",
       "212            % -51.513321          89\n",
       "977         miss -50.996460         275\n",
       "887      reality -50.415108          24\n",
       "1165         rip -48.710472          26\n",
       "97          fans -48.475838          27"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_words_f  = pos_words_f.sort_values('pred',ascending=True)\n",
    "neg_words_f.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
