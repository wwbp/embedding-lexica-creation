{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a new dataset, only modifying the following shall be sufficient. \n",
    "* Import Data\n",
    "    * directory\n",
    "    * file name\n",
    "    * pd.read_csv() if different file type\n",
    "    * data_name\n",
    "    * label_name\n",
    "* Prepare Data\n",
    "    * In get_train_data function, modify the way binary labels are defined.\n",
    "    * Number of posts (iterations) in get_word_data based on your interest\n",
    "* Results\n",
    "    * Modify the way 'keyword' is used based on your binary labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXWy85hSG3ps"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYi2edrSIhlZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xQY8N_XvtGbearJ5X4QryQ</td>\n",
       "      <td>2</td>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UmFMZ8PyXZTY2QcwzsfQYA</td>\n",
       "      <td>1</td>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG2ZaYiOgpr2DK_90pYjNw</td>\n",
       "      <td>5</td>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i6g_oA9Yf9Y31qt0wibXpw</td>\n",
       "      <td>1</td>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6TdNDKywdbjoTkizeMce8A</td>\n",
       "      <td>4</td>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  stars  \\\n",
       "0  xQY8N_XvtGbearJ5X4QryQ      2   \n",
       "1  UmFMZ8PyXZTY2QcwzsfQYA      1   \n",
       "2  LG2ZaYiOgpr2DK_90pYjNw      5   \n",
       "3  i6g_oA9Yf9Y31qt0wibXpw      1   \n",
       "4  6TdNDKywdbjoTkizeMce8A      4   \n",
       "\n",
       "                                                text  \n",
       "0  As someone who has worked with many museums, I...  \n",
       "1  I am actually horrified this place is still in...  \n",
       "2  I love Deagan's. I do. I really do. The atmosp...  \n",
       "3  Dismal, lukewarm, defrosted-tasting \"TexMex\" g...  \n",
       "4  Oh happy day, finally have a Canes near my cas...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/data2/link10/data/yelp/'\n",
    "file_name = 'df1M.tsv'\n",
    "raw_df = pd.read_csv(directory + file_name, delimiter = '\\t')\n",
    "# remove rows with missing values\n",
    "df = raw_df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'text'\n",
    "label_name = 'stars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000000 data.\n",
      "Labels are: [2 1 5 4 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    449091\n",
       "4    210363\n",
       "1    156690\n",
       "3    104973\n",
       "2     78883\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    'There are {} data.'.format(df.shape[0]),\n",
    "    'Labels are: {}'.format(df[label_name].unique()),\n",
    "    sep = '\\n'\n",
    "    )\n",
    "df[label_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLbPIpy6FBNn"
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "id": "h4H-xS4oRs-M",
    "outputId": "7a860939-7f5a-454b-839d-406aa88fd24d"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBe-lTvJUJ7Y"
   },
   "outputs": [],
   "source": [
    "# load the language model\n",
    "nlp = spacy.load('/data2/link10/models/fasttext/en_fasttext_crawl_subword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dCiBEqP8UxPI",
    "outputId": "51aca1ca-5a26-445b-aa83-f079e2348376"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [11:05<00:00, 1503.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000000, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with nlp.disable_pipes():\n",
    "    msg_vectors = np.array([nlp(msg.lower()).vector for msg in tqdm(df[data_name])])\n",
    "msg_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'yelp_fasttext_vectors_subword' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "yelp_fasttext_vectors_subword = msg_vectors\n",
    "%store yelp_fasttext_vectors_subword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding takes huge amount of time, use stored result\n",
    "%store -r yelp_fasttext_vectors_subword\n",
    "msg_vectors = yelp_fasttext_vectors_subword\n",
    "msg_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='stars', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.countplot(x = label_name, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='stars', ylabel='count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df = df.copy()\n",
    "encode_map = {\n",
    "    1: 'negative',\n",
    "    2: 'negative',\n",
    "    3: 'negative',\n",
    "    4: 'positive',\n",
    "    5: 'positive',\n",
    "}\n",
    "new_df[label_name].replace(encode_map, inplace=True)\n",
    "sb.countplot(x = label_name, data=new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use partial data set for training\n",
    "partial = 100000\n",
    "keyword = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([1 if x > keyword else 0 for x in df[label_name]])\n",
    "X_train, X_test, y_train, y_test = train_test_split(msg_vectors[0:partial], labels[0:partial],\n",
    "                                                    test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardize Input (skip for now)\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ts = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "# Y_train_ts = torch.from_numpy(Y_train).type(torch.LongTensor)\n",
    "# X_test_ts = torch.from_numpy(X_test).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test data\n",
    "class testData(Dataset):    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)#\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer Feed-Forward network with BatchNorm and Dropout\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(300, 1024) \n",
    "        self.layer_2 = nn.Linear(1024, 512)\n",
    "        self.layer_3 = nn.Linear(512, 128)\n",
    "        self.layer_out = nn.Linear(128, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "#         self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "#         self.batchnorm2 = nn.BatchNorm1d(512)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "#         x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "#         x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=300, out_features=1024, bias=True)\n",
      "  (layer_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (layer_3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.36483 | Acc: 83.502\n",
      "Epoch 002: | Loss: 0.30745 | Acc: 86.946\n",
      "Epoch 003: | Loss: 0.29720 | Acc: 87.275\n",
      "Epoch 004: | Loss: 0.28701 | Acc: 87.690\n",
      "Epoch 005: | Loss: 0.28490 | Acc: 87.834\n",
      "Epoch 006: | Loss: 0.28324 | Acc: 87.874\n",
      "Epoch 007: | Loss: 0.27871 | Acc: 88.101\n",
      "Epoch 008: | Loss: 0.27589 | Acc: 88.157\n",
      "Epoch 009: | Loss: 0.27372 | Acc: 88.314\n",
      "Epoch 010: | Loss: 0.27151 | Acc: 88.354\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5512,  1152],\n",
       "       [ 1205, 12131]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      6664\n",
      "           1       0.91      0.91      0.91     13336\n",
      "\n",
      "    accuracy                           0.88     20000\n",
      "   macro avg       0.87      0.87      0.87     20000\n",
      "weighted avg       0.88      0.88      0.88     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_data(npl,df):\n",
    "    word_list = []\n",
    "    word_vec = []\n",
    "    word_occr_dict = {}\n",
    "    with nlp.disable_pipes():\n",
    "        for i in tqdm(range(1000000)):\n",
    "            msg = nlp(df.iloc[i][data_name].lower())\n",
    "            for token in msg:\n",
    "                if token.text not in word_list:\n",
    "                    word_list.append(token.text)\n",
    "                    word_vec.append([token.vector])\n",
    "                    word_occr_dict[token.text] = 1\n",
    "                else:\n",
    "                    word_occr_dict[token.text] += 1     \n",
    "    word_array = np.concatenate(np.array(word_vec),0)\n",
    "    word_occr = [word_occr_dict[word] for word in word_list]\n",
    "    return word_list, word_array, word_occr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_list, word_array, word_occr = get_word_data(nlp,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yelp_fasttext_word_subword = [word_list, word_array, word_occr]\n",
    "# %store yelp_fasttext_word_subword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stored result\n",
    "%store -r yelp_fasttext_word_subword\n",
    "word_list = yelp_fasttext_word_subword[0]\n",
    "word_array = yelp_fasttext_word_subword[1]\n",
    "word_occr = yelp_fasttext_word_subword[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word data\n",
    "class wordData(Dataset):    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "word_data = wordData(torch.FloatTensor(word_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_loader = DataLoader(dataset=word_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321423/321423 [02:28<00:00, 2162.18it/s]\n"
     ]
    }
   ],
   "source": [
    "word_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in tqdm(word_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        word_pred = model(X_batch)\n",
    "#         word_pred = torch.sigmoid(word_pred)\n",
    "        word_pred_list.append(word_pred.cpu().numpy())\n",
    "word_pred_list = [a.squeeze().tolist() for a in word_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = pd.DataFrame({'word':word_list,'pred':word_pred_list,'occurrence':word_occr})\n",
    "top_words = top_words.sort_values('pred',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 1000\n",
    "pos_words_f = top_words[top_words['occurrence']>thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pred</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>joy</td>\n",
       "      <td>79.172264</td>\n",
       "      <td>1754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>gem</td>\n",
       "      <td>59.903305</td>\n",
       "      <td>11036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>fav</td>\n",
       "      <td>55.360645</td>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>ease</td>\n",
       "      <td>54.974483</td>\n",
       "      <td>2953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>timely</td>\n",
       "      <td>53.607162</td>\n",
       "      <td>4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>finest</td>\n",
       "      <td>53.021709</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>amazing</td>\n",
       "      <td>51.126606</td>\n",
       "      <td>130807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>able</td>\n",
       "      <td>49.089935</td>\n",
       "      <td>39640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>pleasure</td>\n",
       "      <td>47.391796</td>\n",
       "      <td>4677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6971</th>\n",
       "      <td>thorough</td>\n",
       "      <td>46.703495</td>\n",
       "      <td>5060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>superb</td>\n",
       "      <td>46.146366</td>\n",
       "      <td>4944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>personable</td>\n",
       "      <td>45.980209</td>\n",
       "      <td>5623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>warmly</td>\n",
       "      <td>43.270527</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>jim</td>\n",
       "      <td>43.184113</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>truly</td>\n",
       "      <td>43.034012</td>\n",
       "      <td>16726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>magical</td>\n",
       "      <td>42.798904</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>gift</td>\n",
       "      <td>42.333469</td>\n",
       "      <td>7874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>unique</td>\n",
       "      <td>42.218727</td>\n",
       "      <td>17331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9959</th>\n",
       "      <td>assisted</td>\n",
       "      <td>41.871098</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>loved</td>\n",
       "      <td>41.587124</td>\n",
       "      <td>47297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word       pred  occurrence\n",
       "7519          joy  79.172264        1754\n",
       "4707          gem  59.903305       11036\n",
       "3631          fav  55.360645        2525\n",
       "4044         ease  54.974483        2953\n",
       "3046       timely  53.607162        4460\n",
       "3988       finest  53.021709        1035\n",
       "313       amazing  51.126606      130807\n",
       "1896         able  49.089935       39640\n",
       "1862     pleasure  47.391796        4677\n",
       "6971     thorough  46.703495        5060\n",
       "3983       superb  46.146366        4944\n",
       "4860   personable  45.980209        5623\n",
       "4809       warmly  43.270527        1009\n",
       "1229          jim  43.184113        1788\n",
       "983         truly  43.034012       16726\n",
       "11063     magical  42.798904        1105\n",
       "2077         gift  42.333469        7874\n",
       "1222       unique  42.218727       17331\n",
       "9959     assisted  41.871098        1235\n",
       "670         loved  41.587124       47297"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_words_f.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pred</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>scam</td>\n",
       "      <td>-42.290268</td>\n",
       "      <td>2537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7626</th>\n",
       "      <td>lied</td>\n",
       "      <td>-41.502205</td>\n",
       "      <td>2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>rude</td>\n",
       "      <td>-40.556736</td>\n",
       "      <td>30652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>rudely</td>\n",
       "      <td>-37.032745</td>\n",
       "      <td>2062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>waste</td>\n",
       "      <td>-36.723103</td>\n",
       "      <td>11468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>ex</td>\n",
       "      <td>-34.227276</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>sick</td>\n",
       "      <td>-32.755211</td>\n",
       "      <td>6842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>nor</td>\n",
       "      <td>-32.433567</td>\n",
       "      <td>7077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>yelled</td>\n",
       "      <td>-32.409519</td>\n",
       "      <td>1682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>filthy</td>\n",
       "      <td>-30.667110</td>\n",
       "      <td>2455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>sink</td>\n",
       "      <td>-30.152050</td>\n",
       "      <td>2843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>trash</td>\n",
       "      <td>-29.966311</td>\n",
       "      <td>4365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>idiot</td>\n",
       "      <td>-29.479418</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>refund</td>\n",
       "      <td>-29.267529</td>\n",
       "      <td>7894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>refuse</td>\n",
       "      <td>-28.892380</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9408</th>\n",
       "      <td>wasting</td>\n",
       "      <td>-28.139385</td>\n",
       "      <td>1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11457</th>\n",
       "      <td>ruin</td>\n",
       "      <td>-28.033813</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7925</th>\n",
       "      <td>wasted</td>\n",
       "      <td>-27.828056</td>\n",
       "      <td>3230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11856</th>\n",
       "      <td>hr</td>\n",
       "      <td>-27.472794</td>\n",
       "      <td>1521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>turn</td>\n",
       "      <td>-26.662901</td>\n",
       "      <td>10649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word       pred  occurrence\n",
       "4190      scam -42.290268        2537\n",
       "7626      lied -41.502205        2052\n",
       "1795      rude -40.556736       30652\n",
       "3610    rudely -37.032745        2062\n",
       "854      waste -36.723103       11468\n",
       "4345        ex -34.227276        1063\n",
       "2121      sick -32.755211        6842\n",
       "721        nor -32.433567        7077\n",
       "4366    yelled -32.409519        1682\n",
       "4447    filthy -30.667110        2455\n",
       "10398     sink -30.152050        2843\n",
       "1634     trash -29.966311        4365\n",
       "4094     idiot -29.479418        1236\n",
       "5188    refund -29.267529        7894\n",
       "1954    refuse -28.892380        1945\n",
       "9408   wasting -28.139385        1669\n",
       "11457     ruin -28.033813        1495\n",
       "7925    wasted -27.828056        3230\n",
       "11856       hr -27.472794        1521\n",
       "232       turn -26.662901       10649"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_words_f  = pos_words_f.sort_values('pred',ascending=True)\n",
    "neg_words_f.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "amazon_fasttext_vectors             -> array([[-0.08999809, -0.09236344, -0.05310385, ...\n",
      "amazon_fasttext_word                -> [['i', 'have', 'bought', 'several', 'of', 'the', '\n",
      "amazon_glove_vectors                -> array([[-0.14978772,  0.15294558, -0.09378192, ...\n",
      "amazon_glove_word                   -> [['i', 'have', 'bought', 'several', 'of', 'the', '\n",
      "nrc_bert_vectors                    -> array([[  1.3277535 ,  -0.22097862,  12.090231  , \n",
      "nrc_bert_word                       -> [['thinks', 'that', '@melbahughes', 'had', 'a', 'g\n",
      "nrc_fasttext_vectors                -> array([[ 0.01679   , -0.15144   , -0.02061   , ...\n",
      "nrc_fasttext_word                   -> [['thinks', 'that', '@melbahughes', 'had', 'a', 'g\n",
      "nrc_glove_vectors                   -> array([[ 0.04746217,  0.181698  ,  0.01058619, ...\n",
      "nrc_glove_word                      -> [['thinks', 'that', '@melbahughes', 'had', 'a', 'g\n",
      "yelp_fasttext_vectors               -> array([[-0.03174149, -0.02313265, -0.01704215, ...\n",
      "yelp_fasttext_word                  -> [['as', 'someone', 'who', 'has', 'worked', 'with',\n",
      "yelp_glove_vectors                  -> array([[-8.77902319e-04,  1.61974162e-01, -1.50082\n",
      "yelp_glove_word                     -> [['as', 'someone', 'who', 'has', 'worked', 'with',\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
