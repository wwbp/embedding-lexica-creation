{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a new dataset, only modifying the following shall be sufficient. \n",
    "* Import Data\n",
    "    * directory\n",
    "    * file name\n",
    "    * pd.read_csv() if different file type\n",
    "    * data_name\n",
    "    * label_name\n",
    "* Prepare Data\n",
    "    * In get_train_data function, modify the way binary labels are defined.\n",
    "    * Number of posts (iterations) in get_word_data based on your interest\n",
    "* Results\n",
    "    * Modify the way 'keyword' is used based on your binary labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXWy85hSG3ps"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYi2edrSIhlZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>message</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145353048817012736</td>\n",
       "      <td>Thinks that @melbahughes had a great 50th birt...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144279638024257536</td>\n",
       "      <td>Como una expresiÃ³n tan simple, una sola oraci...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140499585285111809</td>\n",
       "      <td>the moment when you get another follower and y...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145207578270507009</td>\n",
       "      <td>Be the greatest dancer of your life! practice ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139502146390470656</td>\n",
       "      <td>eww.. my moms starting to make her annual rum ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           message_id                                            message  \\\n",
       "0  145353048817012736  Thinks that @melbahughes had a great 50th birt...   \n",
       "1  144279638024257536  Como una expresiÃ³n tan simple, una sola oraci...   \n",
       "2  140499585285111809  the moment when you get another follower and y...   \n",
       "3  145207578270507009  Be the greatest dancer of your life! practice ...   \n",
       "4  139502146390470656  eww.. my moms starting to make her annual rum ...   \n",
       "\n",
       "    emotion  \n",
       "0  surprise  \n",
       "1   sadness  \n",
       "2       joy  \n",
       "3       joy  \n",
       "4   disgust  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/data2/link10/data/nrc/'\n",
    "file_name = 'msgs_tec.csv'\n",
    "raw_df = pd.read_csv(directory + file_name)\n",
    "# remove rows with missing values\n",
    "df = raw_df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'message'\n",
    "label_name = 'emotion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21049 data.\n",
      "Labels are: ['surprise' 'sadness' 'joy' 'disgust' 'fear' 'anger']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "joy         8239\n",
       "surprise    3849\n",
       "sadness     3829\n",
       "fear        2816\n",
       "anger       1555\n",
       "disgust      761\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    'There are {} data.'.format(df.shape[0]),\n",
    "    'Labels are: {}'.format(df[label_name].unique()),\n",
    "    sep = '\\n'\n",
    "    )\n",
    "df[label_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLbPIpy6FBNn"
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "id": "h4H-xS4oRs-M",
    "outputId": "7a860939-7f5a-454b-839d-406aa88fd24d"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBe-lTvJUJ7Y"
   },
   "outputs": [],
   "source": [
    "# # load the language model\n",
    "# nlp = spacy.load('/data2/link10/models/fasttext/en_fasttext_crawl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dCiBEqP8UxPI",
    "outputId": "51aca1ca-5a26-445b-aa83-f079e2348376"
   },
   "outputs": [],
   "source": [
    "# with nlp.disable_pipes():\n",
    "#     msg_vectors = np.array([nlp(msg.lower()).vector for msg in tqdm(df[data_name])])\n",
    "# msg_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nrc_fasttext_vectors = msg_vectors\n",
    "# %store nrc_fasttext_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21049, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding takes huge amount of time, use stored result\n",
    "%store -r nrc_fasttext_vectors\n",
    "msg_vectors = nrc_fasttext_vectors\n",
    "msg_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f27c7bd7a60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAb90lEQVR4nO3df5hdVX3v8ffHBENAgsRMcuNMNKmO2iTWaOamQay/ghCtklRJHR6RoPRO5UaRPtrepPVBam9uucX21kjDbaqYCSIhopCUyo90KtBCIE4gEBJMmRJIpkmTgVYIUqMJ3/vHXnPZTs7MPgmzz5lhPq/nOc/Z57vX2nvtc86c7+y19g9FBGZmZgN5Rb0bYGZmQ5+ThZmZFXKyMDOzQk4WZmZWyMnCzMwKja53A8oyYcKEmDp1ar2bYWY2rGzZsuWpiGjoG3/ZJoupU6fS2dlZ72aYmQ0rkp6sFHc3lJmZFXKyMDOzQk4WZmZWyMnCzMwKOVmYmVkhJwszMyvkZGFmZoWcLMzMrJCThZmZFXrZnsFtLz9nfP2MejfhmN3zuXvq3QSzQeE9CzMzK+RkYWZmhUpNFpJ+T9J2SY9Iul7SiZLGS9oo6bH0fFqu/DJJXZJ2Sjo7F58taVuat0KSymy3mZn9stKShaRG4BKgJSJmAqOAVmAp0BERzUBHeo2k6Wn+DGA+sFLSqLS4q4E2oDk95pfVbjMzO1rZ3VCjgbGSRgMnAXuBBUB7mt8OLEzTC4C1EXEoInYBXcAcSZOBcRGxKSICWJOrY2ZmNVBasoiIfwW+CuwG9gHPRMQdwKSI2JfK7AMmpiqNwJ7cIrpTrDFN940fRVKbpE5JnT09PYO5OWZmI1qZ3VCnke0tTANeC5ws6fyBqlSIxQDxo4MRqyKiJSJaGhqOutGTmZkdpzK7oc4EdkVET0T8Avg+8E5gf+paIj0fSOW7gSm5+k1k3Vbdabpv3MzMaqTMZLEbmCvppHT00jzgUWADsDiVWQysT9MbgFZJYyRNIxvI3py6qg5KmpuWc0GujpmZ1UBpZ3BHxP2SbgQeAA4DDwKrgFcB6yRdRJZQFqXy2yWtA3ak8ksi4kha3MXAamAscGt6mJlZjZR6uY+I+DLw5T7hQ2R7GZXKLweWV4h3AjMHvYFmZlYVn8FtZmaFnCzMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZmJlZIScLMzMr5GRhZmaFnCzMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZmJlZIScLMzMrVFqykPRmSVtzj2clXSppvKSNkh5Lz6fl6iyT1CVpp6Szc/HZkraleSvS7VXNzKxGSksWEbEzImZFxCxgNvA8cBOwFOiIiGagI71G0nSgFZgBzAdWShqVFnc10EZ2X+7mNN/MzGqkVt1Q84B/iYgngQVAe4q3AwvT9AJgbUQciohdQBcwR9JkYFxEbIqIANbk6piZWQ3UKlm0Aten6UkRsQ8gPU9M8UZgT65Od4o1pum+8aNIapPUKamzp6dnEJtvZjaylZ4sJL0SOAf4blHRCrEYIH50MGJVRLREREtDQ8OxNdTMzPpViz2LDwIPRMT+9Hp/6loiPR9I8W5gSq5eE7A3xZsqxM3MrEZqkSzO48UuKIANwOI0vRhYn4u3ShojaRrZQPbm1FV1UNLcdBTUBbk6ZmZWA6PLXLikk4APAL+bC18BrJN0EbAbWAQQEdslrQN2AIeBJRFxJNW5GFgNjAVuTQ8zM6uRUpNFRDwPvKZP7Gmyo6MqlV8OLK8Q7wRmltFGMzMr5jO4zcyskJOFmZkVcrIwM7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrIwM7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK+RkYWZmhUpNFpJeLelGST+W9Kik0yWNl7RR0mPp+bRc+WWSuiTtlHR2Lj5b0rY0b0W6vaqZmdVI2XsWXwNui4i3AG8DHgWWAh0R0Qx0pNdImg60AjOA+cBKSaPScq4G2sjuy92c5puZWY2UliwkjQPeDXwTICJ+HhE/ARYA7alYO7AwTS8A1kbEoYjYBXQBcyRNBsZFxKaICGBNro6ZmdVAmXsWvwL0AN+S9KCkb0g6GZgUEfsA0vPEVL4R2JOr351ijWm6b/woktokdUrq7OnpGdytMTMbwcpMFqOBdwBXR8TbgZ+Supz6UWkcIgaIHx2MWBURLRHR0tDQcKztNTOzfpSZLLqB7oi4P72+kSx57E9dS6TnA7nyU3L1m4C9Kd5UIW5mZjVSWrKIiH8D9kh6cwrNA3YAG4DFKbYYWJ+mNwCtksZImkY2kL05dVUdlDQ3HQV1Qa6OmZnVwOiSl/854DpJrwQeBz5FlqDWSboI2A0sAoiI7ZLWkSWUw8CSiDiSlnMxsBoYC9yaHmZmViOlJouI2Aq0VJg1r5/yy4HlFeKdwMzBbZ2ZmVXLZ3CbmVkhJwszMyvkZGFmZoWcLMzMrJCThZmZFXKyMDOzQk4WZmZWyMnCzMwKOVmYmVkhJwszMyvkZGFmZoWcLMzMrJCThZmZFXKyMDOzQk4WZmZWyMnCzMwKlZosJD0haZukrZI6U2y8pI2SHkvPp+XKL5PUJWmnpLNz8dlpOV2SVqTbq5qZWY3UYs/ifRExKyJ675i3FOiIiGagI71G0nSgFZgBzAdWShqV6lwNtJHdl7s5zTczsxqpRzfUAqA9TbcDC3PxtRFxKCJ2AV3AHEmTgXERsSkiAliTq2NmZjVQdrII4A5JWyS1pdikiNgHkJ4npngjsCdXtzvFGtN03/hRJLVJ6pTU2dPTM4ibYWY2so0ueflnRMReSROBjZJ+PEDZSuMQMUD86GDEKmAVQEtLS8UyZmZ27Erds4iIven5AHATMAfYn7qWSM8HUvFuYEquehOwN8WbKsTNzKxGSksWkk6WdErvNHAW8AiwAVicii0G1qfpDUCrpDGSppENZG9OXVUHJc1NR0FdkKtjZmY1UGY31CTgpnSU62jgOxFxm6QfAeskXQTsBhYBRMR2SeuAHcBhYElEHEnLuhhYDYwFbk0PMzOrkdKSRUQ8DrytQvxpYF4/dZYDyyvEO4GZg91GMzOrTlXdUJI6qomZmdnL04B7FpJOBE4CJqQzrXuPTBoHvLbktpmZ2RBR1A31u8ClZIlhCy8mi2eBvyqxXWZmNoQMmCwi4mvA1yR9LiK+XqM2mZnZEFPVAHdEfF3SO4Gp+ToRsaakdpmZ2RBSVbKQdC3wBmAr0Hs4a+91mszM7GWu2kNnW4Dp6UJ+ZmY2wlR7BvcjwH8psyFmZjZ0VbtnMQHYIWkzcKg3GBHnlNIqMzMbUqpNFpeX2QgzMxvaqj0a6q6yG2JmZkNXtUdDHeTFe0i8EjgB+GlEjCurYWZmNnRUu2dxSv61pIVk96YwM7MR4LjuZxERNwPvH+S2mJnZEFVtN9RHcy9fQXbehc+5MDMbIao9GuojuenDwBPAgkFvjZmZDUnVjll86nhXIGkU0An8a0R8WNJ44Aay60w9Afx2RPxHKrsMuIjskiKXRMTtKT6bF++U9wPg8z6b3Mysdqq9+VGTpJskHZC0X9L3JDVVuY7PA4/mXi8FOiKiGehIr5E0HWgFZgDzgZUp0QBcDbSR3Ze7Oc03M7MaqXaA+1vABrL7WjQCf5tiA0oJ5TeBb+TCC4D2NN0OLMzF10bEoYjYBXQBcyRNBsZFxKa0N7EmV8fMzGqg2mTREBHfiojD6bEaaKii3l8CfwC8kItNioh9AOl5Yoo3Anty5bpTrDFN940fRVKbpE5JnT09PVU0z8zMqlFtsnhK0vmSRqXH+cDTA1WQ9GHgQERsqXIdqhCLAeJHByNWRURLRLQ0NFSTy8zMrBrVHg31aeAq4P+Q/VDfCxQNep8BnCPpQ8CJwDhJ3wb2S5ocEftSF9OBVL4bmJKr3wTsTfGmCnEzM6uRavcs/gRYHBENETGRLHlcPlCFiFgWEU0RMZVs4PofIuJ8srGPxanYYmB9mt4AtEoaI2ka2UD25tRVdVDSXEkCLsjVMTOzGqh2z+LXeg9vBYiIf5f09uNc5xXAOkkXAbuBRWmZ2yWtA3aQncuxJCJ678p3MS8eOntrehyz2b8//G7st+XKC+rdBDOzqpPFKySdljsfYvwx1CUi7gTuTNNPA/P6KbccWF4h3gnMrHZ9I9Xur7y13k04Zq+7bFu9m2BmVaj2B//PgXsl3Ug2ZvHbVPhRNzOzl6dqz+BeI6mT7OKBAj4aETtKbZmZmQ0Zx9KVtINsPMHMzEaY47pEuZmZjSxOFmZmVsjJwszMCjlZmJlZIScLMzMr5GRhZmaFnCzMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZmJlZIScLMzMrVFqykHSipM2SHpK0XdIfp/h4SRslPZaeT8vVWSapS9JOSWfn4rMlbUvzVqTbq5qZWY2UuWdxCHh/RLwNmAXMlzQXWAp0REQz0JFeI2k62b26ZwDzgZWSRqVlXQ20kd2XuznNNzOzGiktWUTmufTyhPQIYAHQnuLtwMI0vQBYGxGHImIX0AXMkTQZGBcRmyIigDW5OmZmVgOljllIGiVpK3AA2BgR9wOTImIfQHqemIo3Anty1btTrDFN941XWl+bpE5JnT09PYO7MWZmI1ipySIijkTELKCJbC9h5gDFK41DxADxSutbFREtEdHS0NBw7A02M7OKanI0VET8BLiTbKxhf+paIj0fSMW6gSm5ak3A3hRvqhA3M7MaKfNoqAZJr07TY4EzgR8DG4DFqdhiYH2a3gC0ShojaRrZQPbm1FV1UNLcdBTUBbk6ZmZWA6NLXPZkoD0d0fQKYF1E3CJpE7BO0kXAbmARQERsl7QO2AEcBpZExJG0rIuB1cBY4Nb0MDOzGiktWUTEw8DbK8SfBub1U2c5sLxCvBMYaLzDzIawq77wt/VuwjH77J9/pN5NGFJ8BreZmRVysjAzs0JOFmZmVsjJwszMCjlZmJlZIScLMzMr5GRhZmaFnCzMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZmJlZIScLMzMr5GRhZmaFnCzMzKxQmbdVnSLph5IelbRd0udTfLykjZIeS8+n5eosk9Qlaaeks3Px2ZK2pXkr0u1VzcysRsrcszgMfCEifhWYCyyRNB1YCnRERDPQkV6T5rUCM4D5wMp0S1aAq4E2svtyN6f5ZmZWI6Uli4jYFxEPpOmDwKNAI7AAaE/F2oGFaXoBsDYiDkXELqALmCNpMjAuIjZFRABrcnXMzKwGajJmIWkq2f247wcmRcQ+yBIKMDEVawT25Kp1p1hjmu4bNzOzGik9WUh6FfA94NKIeHagohViMUC80rraJHVK6uzp6Tn2xpqZWUWlJgtJJ5Aliusi4vspvD91LZGeD6R4NzAlV70J2JviTRXiR4mIVRHREhEtDQ0Ng7chZmYjXJlHQwn4JvBoRPxFbtYGYHGaXgysz8VbJY2RNI1sIHtz6qo6KGluWuYFuTpmZlYDo0tc9hnAJ4Ftkram2B8CVwDrJF0E7AYWAUTEdknrgB1kR1ItiYgjqd7FwGpgLHBrepiZWY2Uliwi4p+oPN4AMK+fOsuB5RXincDMwWudmZkdC5/BbWZmhZwszMyskJOFmZkVcrIwM7NCThZmZlbIycLMzAqVeZ6FmdmIsPz8c+vdhGP2R9++8ZjKe8/CzMwKOVmYmVkhJwszMyvkZGFmZoWcLMzMrJCThZmZFXKyMDOzQk4WZmZWyMnCzMwKOVmYmVmhMu/BfY2kA5IeycXGS9oo6bH0fFpu3jJJXZJ2Sjo7F58taVuatyLdh9vMzGqozD2L1cD8PrGlQEdENAMd6TWSpgOtwIxUZ6WkUanO1UAb0JwefZdpZmYlKy1ZRMTdwL/3CS8A2tN0O7AwF18bEYciYhfQBcyRNBkYFxGbIiKANbk6ZmZWI7Ues5gUEfsA0vPEFG8E9uTKdadYY5ruG69IUpukTkmdPT09g9pwM7ORbKgMcFcah4gB4hVFxKqIaImIloaGhkFrnJnZSFfrZLE/dS2Rng+keDcwJVeuCdib4k0V4mZmVkO1ThYbgMVpejGwPhdvlTRG0jSygezNqavqoKS56SioC3J1zMysRkq7U56k64H3AhMkdQNfBq4A1km6CNgNLAKIiO2S1gE7gMPAkog4khZ1MdmRVWOBW9PDzMxqqLRkERHn9TNrXj/llwPLK8Q7gZmD2DQzMztGvge32RBx17vfU+8mHJP33H1XvZtgNTRUjoYyM7MhzMnCzMwKOVmYmVkhJwszMyvkZGFmZoWcLMzMrJCThZmZFXKyMDOzQk4WZmZWyMnCzMwKOVmYmVkhJwszMyvkZGFmZoWcLMzMrJCThZmZFRo2yULSfEk7JXVJWlrv9piZjSTDIllIGgX8FfBBYDpwnqTp9W2VmdnIMSySBTAH6IqIxyPi58BaYEGd22RmNmIoIurdhkKSzgXmR8TvpNefBH49Ij7bp1wb0JZevhnYWcNmTgCequH6aunlvG3g7RvuvH2D6/UR0dA3OFzuwa0KsaOyXESsAlaV35yjSeqMiJZ6rLtsL+dtA2/fcOftq43h0g3VDUzJvW4C9tapLWZmI85wSRY/ApolTZP0SqAV2FDnNpmZjRjDohsqIg5L+ixwOzAKuCYitte5WX3VpfurRl7O2wbevuHO21cDw2KA28zM6mu4dEOZmVkdOVmYmVkhJ4uSSfqBpFfXux3VkjRV0iP1bkdZJN1b7zYcL0mXS/qipK9IOrMG61tY7yslSLpE0qOSrqtnO2yYDHAPJZJGR8ThKsqJbEzoQzVollUpIt5Z7za8VBFxWY1WtRC4BdhRo/VV8t+BD0bEruNdgKRREXFkENs05OV+f14YrGWO2D0LSSdL+jtJD0l6RNLHJT0haUKa3yLpzjR9uaRVku4A1ki6UNJ6Sbelixt+OZWbmv4LWgk8AEzpXWal9aU6syXdJWmLpNslTS5x+y6T9KP0elX6QvW24SFJm4AluWVcKOn7aTsfk/RnuXlnSdok6QFJ35X0qhS/QtIOSQ9L+mqKLUrrfEjS3YOxfcdL0nPKXJnatC33WVwraUGu7HWSzqlfa0HSH6Xv2N+TXZUASavTVQ36e7/fIOm+9Fl/RdJzKf5eSbfkln2VpAsrLUfSO4FzgCslbZX0htpuOUj6v8CvABvS+3BN2qYHez+n9Df3j+l7+EBqd++2/lDSd4BttW57fyTdnP7Wtyu74kTvd3J5+vu4T9KkFK/4OaZ5v5/iD0v64xQ76vdnUBsfESPyAXwM+Jvc61OBJ4AJ6XULcGeavhzYAoxNry8E9gGvAcYCj6TyU4EXgLm55T5Bdrp+pfWdANwLNKTYx8kOCy5r+8bnXl8LfCRNPwy8J01fCTyS287HU90TgSfJvoATgLuBk1O5/wFcBownu8RK71F2r07P24DGfKyOn/tz6b3ZSHYY9iRgNzAZeA9wc+792gWMrmNbZ6f37iRgHNAFfBFYDZw7wPt9C3Bemv4M8Fyafi9wS275V6XPuL/lrAbOrfPn1fv387+A83vbB/wzcHJ6b05M8WagM7etPwWm1bP9FbZnfHru/d14DdnVKHr/Fv8M+FLB53gW2eG0IvuH/xbg3VT4/RnMx4jdsyD7IzxT0v+W9BsR8UxB+Q0R8Z+51xsj4ukU+z7wrhR/MiLuq3J9bwZmAhslbQW+RHZ2+mCotL73Sbpf0jbg/cAMSaeS/Tjclepd22c5HRHxTET8jKw74vXAXLKr/96T2r04xZ8FfgZ8Q9JHgefTMu4BVkv6b2Q/0PX2LuD6iDgSEfuBu4D/mt6DN0qaCJwHfC+q6HIs0W8AN0XE8xHxLEefiNrf+3068N00/Z0q1tPfcoaSs4Cl6ft2J9k/L68j+4frb9J3+rtk38tem+MldF+V5BJJDwH3kf3j1Qz8nOwHH7J/Sqem6f4+x7PS40GyPYi3pOVA/78/L9mIHbOIiH+WNBv4EPCnyrqYDvNi19yJfar8tO8i+nndt9xA67sJ2B4Rpx/nZvSrn/UtAVoiYo+ky8m2URW2Je9QbvoI2XdGZMnyvL6FJc0B5pGdZf9Z4P0R8RlJvw78JrBV0qyIePolb+Txq3StsV7XAp8ga/+na9OcAfX72UR2supR7/cAy8p/vyF9x49jOfUg4GMR8UsXB03f4/3A28i27We52RX/FutF0nuBM4HTI+J5Zd3cJwK/iLTLwIt/YwMuCvjTiPjrPsufSonbPGL3LCS9Fng+Ir4NfBV4B9ku7+xU5GMFi/iApPGSxpINBN5zHOvbCTRIOj2VOUHSjOPcpGrWB/BUGl84FyAifgI8I6l3z+gTVSz+PuAMSW9M6zpJ0pvSck+NiB8AlwKz0vw3RMT9kQ3MPsVg96Ueu7uBj0saJamBbBd+c5q3mqztRP2vEnA38FuSxko6BfhIfmZ/7zfZ59P7/W3NVXkSmC5pTNqjnFewnIPAKYO/WcflduBz0v8fZ3t7ip8K7ItsIPeTDI091/6cCvxHShRvIdtDH0h/n+PtwKf14jhhY9obLtWI3bMA3ko2ePcC8AvgYrJ+xG9K+kPg/oL6/0T2X+gbge9ERGfK7FWvLyJ+ngYqV6Q/3tHAXwKD8SNVafsWknVPPUF2va1enwKukfQ82RdxQBHRkwZGr5c0JoW/RPbjsl5S7x7L76V5V0pqTrEO4KGXtmkvSZDt0Z2e2hHAH0TEvwFExH5JjwI316+JmYh4QNINwFayH/p/7FPkFCq/35cC35b0BeDvgGfS8vZIWkc2RvUYWTfGQMtZS9bFcwnZ2MW/lLCZ1foTsr+Nh1PCeAL4MLAS+J6kRcAPGWJ7E33cBnxG0sNk/ygWdRf19zneIelXgU0pdz4HnE+2V1IaX+7jOKQfypbocz8NG9okvQZ4ICJeP0CZk8gS6juqGMcaktI2/GdEhKRWskFS3yxsmBlqn+NI3rOwESR1y91J1iXXX5kzgWuAvxiuiSKZDVyV/gP/CUNj7MWO3ZD6HL1nYWZmhUbsALeZmVXPycLMzAo5WZiZWSEnC7M6kDRL0odyr8+RtLSebTIbiAe4zerAh1/bcOM9C7MqSDpf0mZlV2D963T293Pp2ltbJP29pDmS7pT0uNLVaiWdKOlbyq5u+6Ck90l6JfAVsrPItyq7IvCFkq5KdV4vqUPZFUU7JL0uxVdLWiHp3rSOc+v3jthI42RhViCdLftx4IyImEV2puwnyK56emdEzCY7e/1/Ah8AfossGUC65HtEvJXs4oTtZH93lwE3RMSsiLihzyqvAtZExK8B1wErcvMmk10I8cPAFYO8qWb98kl5ZsXmkZ0g9aN0eYWxwAGyq4XelspsAw5FxC/SFVCnpvi7gK8DRMSPJT0JvKlgfacDH03T15JdtrrXzek6SDuU7ntgVgtOFmbFBLRHxLJfCkpfzF0t9AXSFXoj4gVJo3N1X6r8wGL+KsCDsWyzqrgbyqxYB3Bu75U909WG+72+VB93k67kK+lNZPdg2MnAV3S9lxevMvoJsotWmtWVk4VZgYjYQXZV3TvSFUM3ko0dVGMlMCp1Td0AXBgRh8iukDq9d4C7T51LgE+ldX0S+PxgbIfZS+FDZ83MrJD3LMzMrJCThZmZFXKyMDOzQk4WZmZWyMnCzMwKOVmYmVkhJwszMyv0/wBq6oWdmqQ5ngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.countplot(x = label_name, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'joy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([1 if x == keyword else 0 for x in df[label_name]])\n",
    "X_train, X_test, y_train, y_test = train_test_split(msg_vectors, labels,\n",
    "                                                    test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardize Input (skip for now)\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ts = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "# Y_train_ts = torch.from_numpy(Y_train).type(torch.LongTensor)\n",
    "# X_test_ts = torch.from_numpy(X_test).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test data\n",
    "class testData(Dataset):    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)#\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer Feed-Forward network with BatchNorm and Dropout\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(300, 1024) \n",
    "        self.layer_2 = nn.Linear(1024, 512)\n",
    "        self.layer_3 = nn.Linear(512, 128)\n",
    "        self.layer_out = nn.Linear(128, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "#         self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "#         self.batchnorm2 = nn.BatchNorm1d(512)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "#         x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "#         x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=300, out_features=1024, bias=True)\n",
      "  (layer_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (layer_3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.54663 | Acc: 72.583\n",
      "Epoch 002: | Loss: 0.48017 | Acc: 77.235\n",
      "Epoch 003: | Loss: 0.44858 | Acc: 79.424\n",
      "Epoch 004: | Loss: 0.41629 | Acc: 80.902\n",
      "Epoch 005: | Loss: 0.37476 | Acc: 83.591\n",
      "Epoch 006: | Loss: 0.32653 | Acc: 86.205\n",
      "Epoch 007: | Loss: 0.27779 | Acc: 88.470\n",
      "Epoch 008: | Loss: 0.23290 | Acc: 90.530\n",
      "Epoch 009: | Loss: 0.18722 | Acc: 92.424\n",
      "Epoch 010: | Loss: 0.15457 | Acc: 94.053\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2048,  486],\n",
       "       [ 495, 1181]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      2534\n",
      "           1       0.71      0.70      0.71      1676\n",
      "\n",
      "    accuracy                           0.77      4210\n",
      "   macro avg       0.76      0.76      0.76      4210\n",
      "weighted avg       0.77      0.77      0.77      4210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_data(npl,df):\n",
    "    word_list = []\n",
    "    word_vec = []\n",
    "    word_occr_dict = {}\n",
    "    with nlp.disable_pipes():\n",
    "        for i in tqdm(range(1000000)):\n",
    "            msg = nlp(df.iloc[i][data_name].lower())\n",
    "            for token in msg:\n",
    "                if token.text not in word_list:\n",
    "                    word_list.append(token.text)\n",
    "                    word_vec.append([token.vector])\n",
    "                    word_occr_dict[token.text] = 1\n",
    "                else:\n",
    "                    word_occr_dict[token.text] += 1     \n",
    "    word_array = np.concatenate(np.array(word_vec),0)\n",
    "    word_occr = [word_occr_dict[word] for word in word_list]\n",
    "    return word_list, word_array, word_occr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_list, word_array, word_occr = get_word_data(nlp,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nrc_fasttext_word = [word_list, word_array, word_occr]\n",
    "# %store nrc_fasttext_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stored result\n",
    "%store -r nrc_fasttext_word\n",
    "word_list = nrc_fasttext_word[0]\n",
    "word_array = nrc_fasttext_word[1]\n",
    "word_occr = nrc_fasttext_word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word data\n",
    "class wordData(Dataset):    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "word_data = wordData(torch.FloatTensor(word_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_loader = DataLoader(dataset=word_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33451/33451 [00:16<00:00, 2075.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "word_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in tqdm(word_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        word_pred = model(X_batch)\n",
    "#         word_pred = torch.sigmoid(word_pred)\n",
    "        word_pred_list.append(word_pred.cpu().numpy())\n",
    "word_pred_list = [a.squeeze().tolist() for a in word_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = pd.DataFrame({'word':word_list,'pred':word_pred_list,'occurrence':word_occr})\n",
    "top_words = top_words.sort_values('pred',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 20\n",
    "pos_words_f = top_words[top_words['occurrence']>thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pred</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>joy</td>\n",
       "      <td>143.816574</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6242</th>\n",
       "      <td>joyful</td>\n",
       "      <td>118.754517</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>smile</td>\n",
       "      <td>85.137367</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>blessed</td>\n",
       "      <td>78.775780</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386</th>\n",
       "      <td>blessings</td>\n",
       "      <td>76.089806</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>grateful</td>\n",
       "      <td>73.782272</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>laughter</td>\n",
       "      <td>72.931351</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>brings</td>\n",
       "      <td>72.603622</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>tea</td>\n",
       "      <td>71.146675</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>smiles</td>\n",
       "      <td>68.886711</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>sore</td>\n",
       "      <td>67.031265</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cheer</td>\n",
       "      <td>63.549580</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>train</td>\n",
       "      <td>63.008858</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>grace</td>\n",
       "      <td>57.562733</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>fill</td>\n",
       "      <td>57.441536</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5141</th>\n",
       "      <td>gratitude</td>\n",
       "      <td>57.290176</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>energy</td>\n",
       "      <td>57.145359</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>wrapping</td>\n",
       "      <td>57.029945</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6982</th>\n",
       "      <td>thankful</td>\n",
       "      <td>55.925648</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>bus</td>\n",
       "      <td>55.896996</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word        pred  occurrence\n",
       "233         joy  143.816574         322\n",
       "6242     joyful  118.754517          25\n",
       "1408      smile   85.137367         120\n",
       "5216    blessed   78.775780          46\n",
       "7386  blessings   76.089806          21\n",
       "3314   grateful   73.782272          24\n",
       "683    laughter   72.931351          24\n",
       "2013     brings   72.603622          94\n",
       "3310        tea   71.146675          38\n",
       "3211     smiles   68.886711          23\n",
       "5319       sore   67.031265          22\n",
       "31        cheer   63.549580          37\n",
       "1548      train   63.008858          59\n",
       "952       grace   57.562733          27\n",
       "8199       fill   57.441536          30\n",
       "5141  gratitude   57.290176          29\n",
       "1563     energy   57.145359          23\n",
       "5114   wrapping   57.029945          22\n",
       "6982   thankful   55.925648          68\n",
       "408         bus   55.896996          91"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joy\n",
    "pos_words_f.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pred</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>afraid</td>\n",
       "      <td>-128.562332</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>courage</td>\n",
       "      <td>-121.689018</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>fear</td>\n",
       "      <td>-114.170532</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>regret</td>\n",
       "      <td>-112.604843</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>scary</td>\n",
       "      <td>-108.702446</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>scared</td>\n",
       "      <td>-106.665283</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>gay</td>\n",
       "      <td>-101.249245</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>miss</td>\n",
       "      <td>-99.415459</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>surprise</td>\n",
       "      <td>-98.792885</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>respect</td>\n",
       "      <td>-98.363312</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>missing</td>\n",
       "      <td>-96.913651</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>killed</td>\n",
       "      <td>-84.957138</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>surprised</td>\n",
       "      <td>-78.646049</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>grade</td>\n",
       "      <td>-78.388275</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616</th>\n",
       "      <td>showed</td>\n",
       "      <td>-78.156715</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>reality</td>\n",
       "      <td>-75.442802</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>factor</td>\n",
       "      <td>-75.220535</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>memories</td>\n",
       "      <td>-74.600761</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>niggas</td>\n",
       "      <td>-73.622513</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>shows</td>\n",
       "      <td>-72.469589</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word        pred  occurrence\n",
       "1502     afraid -128.562332         422\n",
       "5710    courage -121.689018          36\n",
       "385        fear -114.170532         367\n",
       "944      regret -112.604843          23\n",
       "2485      scary -108.702446          21\n",
       "695      scared -106.665283         124\n",
       "3303        gay -101.249245          44\n",
       "976        miss  -99.415459         275\n",
       "1809   surprise  -98.792885         186\n",
       "4641    respect  -98.363312          22\n",
       "2095    missing  -96.913651          75\n",
       "4733     killed  -84.957138          30\n",
       "2119  surprised  -78.646049          23\n",
       "2860      grade  -78.388275          22\n",
       "6616     showed  -78.156715          21\n",
       "886     reality  -75.442802          24\n",
       "2064     factor  -75.220535          57\n",
       "3294   memories  -74.600761          33\n",
       "2890     niggas  -73.622513          30\n",
       "3751      shows  -72.469589          30"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_words_f  = pos_words_f.sort_values('pred',ascending=True)\n",
    "neg_words_f.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
