{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a new dataset, only modifying the following shall be sufficient. \n",
    "* Import Data\n",
    "    * directory\n",
    "    * file name\n",
    "    * pd.read_csv() if different file type\n",
    "    * data_name\n",
    "    * label_name\n",
    "* Prepare Data\n",
    "    * In get_train_data function, modify the way binary labels are defined.\n",
    "    * Number of posts (iterations) in get_word_data based on your interest\n",
    "* Results\n",
    "    * Modify the way 'keyword' is used based on your binary labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXWy85hSG3ps"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYi2edrSIhlZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xQY8N_XvtGbearJ5X4QryQ</td>\n",
       "      <td>2</td>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UmFMZ8PyXZTY2QcwzsfQYA</td>\n",
       "      <td>1</td>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG2ZaYiOgpr2DK_90pYjNw</td>\n",
       "      <td>5</td>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i6g_oA9Yf9Y31qt0wibXpw</td>\n",
       "      <td>1</td>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6TdNDKywdbjoTkizeMce8A</td>\n",
       "      <td>4</td>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  stars  \\\n",
       "0  xQY8N_XvtGbearJ5X4QryQ      2   \n",
       "1  UmFMZ8PyXZTY2QcwzsfQYA      1   \n",
       "2  LG2ZaYiOgpr2DK_90pYjNw      5   \n",
       "3  i6g_oA9Yf9Y31qt0wibXpw      1   \n",
       "4  6TdNDKywdbjoTkizeMce8A      4   \n",
       "\n",
       "                                                text  \n",
       "0  As someone who has worked with many museums, I...  \n",
       "1  I am actually horrified this place is still in...  \n",
       "2  I love Deagan's. I do. I really do. The atmosp...  \n",
       "3  Dismal, lukewarm, defrosted-tasting \"TexMex\" g...  \n",
       "4  Oh happy day, finally have a Canes near my cas...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/data1/link10/yelp/'\n",
    "file_name = 'df1M.tsv'\n",
    "raw_df = pd.read_csv(directory + file_name, delimiter = '\\t')\n",
    "# remove rows with missing values\n",
    "df = raw_df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'text'\n",
    "label_name = 'stars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000000 data.\n",
      "Labels are: [2 1 5 4 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    449091\n",
       "4    210363\n",
       "1    156690\n",
       "3    104973\n",
       "2     78883\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    'There are {} data.'.format(df.shape[0]),\n",
    "    'Labels are: {}'.format(df[label_name].unique()),\n",
    "    sep = '\\n'\n",
    "    )\n",
    "df[label_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLbPIpy6FBNn"
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "id": "h4H-xS4oRs-M",
    "outputId": "7a860939-7f5a-454b-839d-406aa88fd24d"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBe-lTvJUJ7Y"
   },
   "outputs": [],
   "source": [
    "# # load the language model\n",
    "# nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dCiBEqP8UxPI",
    "outputId": "51aca1ca-5a26-445b-aa83-f079e2348376"
   },
   "outputs": [],
   "source": [
    "# with nlp.disable_pipes():\n",
    "#     msg_vectors = np.array([nlp(msg.lower()).vector for msg in tqdm(df[data_name])])\n",
    "# msg_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yelp_glove_vectors = msg_vectors\n",
    "# %store yelp_glove_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding takes huge amount of time, use stored result\n",
    "%store -r yelp_glove_vectors\n",
    "msg_vectors = yelp_glove_vectors\n",
    "msg_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f24ebaab9a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATTElEQVR4nO3df8yd5X3f8fcHmxKaBALBMGKzGS1WNaBZUjzDxtaucWS8JQ2oI5krEazOkzdEOqJ1q2CbygpDC+sP2qQJEiouhkQFl7QNTceYZZJGSSlgJyTUUIbVMGLhYSemhHSC1c53f5zrkY/N4ycHx9dzP378fklH5z7fc1/X8z3nD39839d9zklVIUnS0XbC0A1IkuYnA0aS1IUBI0nqwoCRJHVhwEiSulg4dANzxRlnnFFLly4dug1JOqZs27btW1W1aLrnDJhm6dKlbN26deg2JOmYkuR/H+45T5FJkrowYCRJXRgwkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrrwk/ySdBT95s//4dAtdPHhX/2p1z3GIxhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpi+4Bk2RBkq8m+Vx7fHqSzUmeafenje17fZIdSZ5OculY/cIkT7TnPpYkrX5Skntb/ZEkS8fGrG1/45kka3u/TknSwWbjCOZa4Kmxx9cBW6pqGbClPSbJecAa4HxgNfDJJAvamNuA9cCydlvd6uuAF6vq7cCtwC1trtOBG4CLgBXADeNBJknqr2vAJFkCvBf4rbHyZcDGtr0RuHysfk9VvVpV3wB2ACuSnA2cUlUPV1UBdx0yZmqu+4CV7ejmUmBzVe2tqheBzRwIJUnSLOh9BPPrwC8A3xurnVVVuwDa/Zmtvhj45th+O1ttcds+tH7QmKraB7wEvHWGuQ6SZH2SrUm27tmz50henyTpMLoFTJL3AburatukQ6ap1Qz1Ix1zoFB1e1Utr6rlixYtmrBNSdIkeh7BXAK8P8mzwD3Au5N8Cnihnfai3e9u++8EzhkbvwR4vtWXTFM/aEyShcCpwN4Z5pIkzZJuAVNV11fVkqpaymjx/qGquhK4H5i6qmst8Nm2fT+wpl0Zdi6jxfxH22m0l5Nc3NZXrjpkzNRcV7S/UcCDwKokp7XF/VWtJkmaJQsH+JsfBTYlWQc8B3wAoKq2J9kEPAnsA66pqv1tzNXAncDJwAPtBnAHcHeSHYyOXNa0ufYmuQl4rO13Y1Xt7f3CJEkHzErAVNUXgC+07W8DKw+z383AzdPUtwIXTFN/hRZQ0zy3AdhwpD1Lkn4wfpJfktSFASNJ6sKAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrowYCRJXXQLmCRvSPJokq8l2Z7kl1r99CSbkzzT7k8bG3N9kh1Jnk5y6Vj9wiRPtOc+liStflKSe1v9kSRLx8asbX/jmSRre71OSdL0eh7BvAq8u6r+LvBOYHWSi4HrgC1VtQzY0h6T5DxgDXA+sBr4ZJIFba7bgPXAsnZb3errgBer6u3ArcAtba7TgRuAi4AVwA3jQSZJ6q9bwNTId9vDE9utgMuAja2+Ebi8bV8G3FNVr1bVN4AdwIokZwOnVNXDVVXAXYeMmZrrPmBlO7q5FNhcVXur6kVgMwdCSZI0C7quwSRZkORxYDejf/AfAc6qql0A7f7Mtvti4Jtjw3e22uK2fWj9oDFVtQ94CXjrDHMd2t/6JFuTbN2zZ88P8lIlSYfoGjBVtb+q3gksYXQ0csEMu2e6KWaoH+mY8f5ur6rlVbV80aJFM7QmSXq9ZuUqsqr6S+ALjE5TvdBOe9Hud7fddgLnjA1bAjzf6kumqR80JslC4FRg7wxzSZJmSc+ryBYleUvbPhl4D/DnwP3A1FVda4HPtu37gTXtyrBzGS3mP9pOo72c5OK2vnLVIWOm5roCeKit0zwIrEpyWlvcX9VqkqRZsrDj3GcDG9uVYCcAm6rqc0keBjYlWQc8B3wAoKq2J9kEPAnsA66pqv1trquBO4GTgQfaDeAO4O4kOxgduaxpc+1NchPwWNvvxqra2/G1SpIO0S1gqurrwLumqX8bWHmYMTcDN09T3wq8Zv2mql6hBdQ0z20ANry+riVJR4uf5JckdWHASJK6MGAkSV0YMJKkLgwYSVIXBowkqQsDRpLUhQEjSerCgJEkdWHASJK6MGAkSV0YMJKkLgwYSVIXEwVMki2T1CRJmjLj1/UneQPww8AZ7Ye7pn6K+BTgbZ17kyQdw77f78H8K+AjjMJkGwcC5jvAJzr2JUk6xs0YMFX1G8BvJPm5qvr4LPUkSZoHJvpFy6r6eJJ/ACwdH1NVd3XqS5J0jJsoYJLcDfxt4HFgfysXYMBIkqY1UcAAy4Hzqqp6NiNJmj8m/RzMnwF/o2cjkqT5ZdIjmDOAJ5M8Crw6Vayq93fpSpJ0zJs0YP5zzyYkSfPPpFeR/XHvRiRJ88ukV5G9zOiqMYAfAk4E/qqqTunVmCTp2DbpEcybxx8nuRxY0aUjSdK8cETfplxVfwC8+yj3IkmaRyY9RfbTYw9PYPS5GD8TI0k6rEmvIvupse19wLPAZUe9G0nSvDHpGszP9m5EkjS/TPqDY0uS/H6S3UleSPKZJEt6NydJOnZNusj/28D9jH4XZjHwh60mSdK0Jg2YRVX121W1r93uBBZ17EuSdIybNGC+leTKJAva7Urg2z0bkyQd2yYNmH8BfBD4P8Au4ArAhX9J0mFNepnyTcDaqnoRIMnpwK8wCh5Jkl5j0oB5x1S4AFTV3iTv6tSTpGPMH//4TwzdQhc/8UW/5/cHMekpshOSnDb1oB3BzBhOSc5J8vkkTyXZnuTaqbFJNid5pt2Pz3t9kh1Jnk5y6Vj9wiRPtOc+liStflKSe1v9kSRLx8asbX/jmSRrJ3ydkqSjZNKA+VXgT5LclORG4E+A//Z9xuwDfr6q/g5wMXBNkvOA64AtVbUM2NIe055bA5wPrAY+mWRBm+s2YD2wrN1Wt/o64MWqejtwK3BLm+t04AbgIkZfynnDeJBJkvqbKGCq6i7gnwEvAHuAn66qu7/PmF1V9ZW2/TLwFKPP0FwGbGy7bQQub9uXAfdU1atV9Q1gB7AiydnAKVX1cFUVcNchY6bmug9Y2Y5uLgU2V9XedmpvMwdCSZI0CyZdg6GqngSePJI/0k5dvQt4BDirqna1OXclObPtthj407FhO1vtr9v2ofWpMd9sc+1L8hLw1vH6NGMkSbPgiL6u//VI8ibgM8BHquo7M+06Ta1mqB/pmPHe1ifZmmTrnj17ZmhNkvR6dQ2YJCcyCpdPV9XvtfIL7bQX7X53q+8EzhkbvgR4vtWXTFM/aEyShcCpwN4Z5jpIVd1eVcuravmiRX4xgSQdTd0Cpq2F3AE8VVW/NvbU/cDUVV1rgc+O1de0K8POZbSY/2g7nfZykovbnFcdMmZqriuAh9o6zYPAqiSntcX9Va0mSZolE6/BHIFLgA8BTyR5vNX+A/BRYFOSdcBzwAcAqmp7kk2M1nn2AddU1f427mrgTuBk4IF2g1GA3Z1kB6MjlzVtrr1JbgIea/vdWFV7e71QSdJrdQuYqvoS06+FAKw8zJibgZunqW8FLpim/gotoKZ5bgOwYdJ+JUlHV/dFfknS8cmAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpi54/ODZvXPjv7xq6hS62/fJVQ7cgaR7zCEaS1IUBI0nqwoCRJHVhwEiSujBgJEldGDCSpC4MGElSFwaMJKkLA0aS1IUBI0nqwoCRJHVhwEiSujBgJEldGDCSpC4MGElSFwaMJKkLA0aS1IUBI0nqwoCRJHVhwEiSujBgJEldGDCSpC4W9po4yQbgfcDuqrqg1U4H7gWWAs8CH6yqF9tz1wPrgP3Av6mqB1v9QuBO4GTgvwPXVlUlOQm4C7gQ+Dbwz6vq2TZmLfCfWiv/pao29nqdOn5d8vFLhm6hiy//3JeHbkHzRM8jmDuB1YfUrgO2VNUyYEt7TJLzgDXA+W3MJ5MsaGNuA9YDy9ptas51wItV9XbgVuCWNtfpwA3ARcAK4IYkp3V4fZKkGXQLmKr6IrD3kPJlwNTRxEbg8rH6PVX1alV9A9gBrEhyNnBKVT1cVcXoiOXyaea6D1iZJMClwOaq2tuOjjbz2qCTJHU222swZ1XVLoB2f2arLwa+ObbfzlZb3LYPrR80pqr2AS8Bb51hrtdIsj7J1iRb9+zZ8wO8LEnSoebKIn+mqdUM9SMdc3Cx6vaqWl5VyxctWjRRo5Kkycx2wLzQTnvR7ne3+k7gnLH9lgDPt/qSaeoHjUmyEDiV0Sm5w80lSZpFsx0w9wNr2/Za4LNj9TVJTkpyLqPF/EfbabSXk1zc1leuOmTM1FxXAA+1dZoHgVVJTmuL+6taTZI0i3pepvw7wD8Gzkiyk9GVXR8FNiVZBzwHfACgqrYn2QQ8CewDrqmq/W2qqzlwmfID7QZwB3B3kh2MjlzWtLn2JrkJeKztd2NVHXqxgSSps24BU1U/c5inVh5m/5uBm6epbwUumKb+Ci2gpnluA7Bh4mYlSUfdXFnklyTNMwaMJKkLA0aS1EW3NRjNT8/d+KNDt9DF3/zFJ4ZuQZp3PIKRJHVhwEiSujBgJEldGDCSpC4MGElSFwaMJKkLA0aS1IUBI0nqwoCRJHVhwEiSujBgJEldGDCSpC4MGElSFwaMJKkLA0aS1IUBI0nqwoCRJHVhwEiSujBgJEldGDCSpC4MGElSFwaMJKkLA0aS1IUBI0nqwoCRJHVhwEiSujBgJEldGDCSpC4MGElSFwaMJKkLA0aS1IUBI0nqwoCRJHUxrwMmyeokTyfZkeS6ofuRpOPJvA2YJAuATwD/BDgP+Jkk5w3blSQdP+ZtwAArgB1V9RdV9f+Ae4DLBu5Jko4bqaqhe+giyRXA6qr6l+3xh4CLqurDY/usB9a3hz8CPD3rjb7WGcC3hm5ijvC9OMD34gDfiwPmwnvxt6pq0XRPLJztTmZRpqkdlKZVdTtw++y0M5kkW6tq+dB9zAW+Fwf4Xhzge3HAXH8v5vMpsp3AOWOPlwDPD9SLJB135nPAPAYsS3Jukh8C1gD3D9yTJB035u0psqral+TDwIPAAmBDVW0fuK1JzKlTdgPzvTjA9+IA34sD5vR7MW8X+SVJw5rPp8gkSQMyYCRJXRgwc0SSDUl2J/mzoXsZUpJzknw+yVNJtie5duiehpLkDUkeTfK19l780tA9DS3JgiRfTfK5oXsZUpJnkzyR5PEkW4fu53Bcg5kjkvw48F3grqq6YOh+hpLkbODsqvpKkjcD24DLq+rJgVubdUkCvLGqvpvkROBLwLVV9acDtzaYJP8WWA6cUlXvG7qfoSR5FlheVUN/yHJGHsHMEVX1RWDv0H0Mrap2VdVX2vbLwFPA4mG7GkaNfLc9PLHdjtv/ESZZArwX+K2he9FkDBjNWUmWAu8CHhm2k+G0U0KPA7uBzVV13L4XwK8DvwB8b+hG5oAC/meSbe0rr+YkA0ZzUpI3AZ8BPlJV3xm6n6FU1f6qeiejb6JYkeS4PH2a5H3A7qraNnQvc8QlVfVjjL4t/pp2in3OMWA057T1hs8An66q3xu6n7mgqv4S+AKweuBWhnIJ8P629nAP8O4knxq2peFU1fPtfjfw+4y+PX7OMWA0p7SF7TuAp6rq14buZ0hJFiV5S9s+GXgP8OfDdjWMqrq+qpZU1VJGX/v0UFVdOXBbg0jyxnYBDEneCKwC5uTVpwbMHJHkd4CHgR9JsjPJuqF7GsglwIcY/Q/18Xb7p0M3NZCzgc8n+Tqj79bbXFXH9eW5AuAs4EtJvgY8CvxRVf2PgXualpcpS5K68AhGktSFASNJ6sKAkSR1YcBIkrowYCRJXRgw0hyR5CNJfnjoPqSjxcuUpTniSL4hN8mCqtrfryvpyC0cugHpeNQ+gb2J0XeMLQB+F3gbow9WfquqfjLJbcDfA04G7quqG9rYZ4ENjD7B/ZtJzgT+NbAPeLKq1sz265GmY8BIw1gNPF9V7wVIcirws8BPjh3B/Meq2ptkAbAlyTuq6uvtuVeq6h+2sc8D51bVq1NfLSPNBa7BSMN4AnhPkluS/KOqemmafT6Y5CvAV4HzgfPGnrt3bPvrwKeTXMnoKEaaEwwYaQBV9b+ACxkFzX9N8ovjzyc5F/h3wMqqegfwR8Abxnb5q7Ht9wKfaPNtS+KZCc0JBow0gCRvA/5vVX0K+BXgx4CXgTe3XU5hFCIvJTmL0e9+TDfPCcA5VfV5Rj/G9RbgTZ3blybi/3SkYfwo8MtJvgf8NXA18PeBB5Lsaov8XwW2A38BfPkw8ywAPtXWcALc2n47RhqclylLkrrwFJkkqQsDRpLUhQEjSerCgJEkdWHASJK6MGAkSV0YMJKkLv4///Br5PQLrAQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.countplot(x = label_name, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2561df1b50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df = df.copy()\n",
    "encode_map = {\n",
    "    1: 'negative',\n",
    "    2: 'negative',\n",
    "    3: 'negative',\n",
    "    4: 'positive',\n",
    "    5: 'positive',\n",
    "}\n",
    "new_df[label_name].replace(encode_map, inplace=True)\n",
    "sb.countplot(x = label_name, data=new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use partial data set for training\n",
    "partial = 100000\n",
    "keyword = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([1 if x > keyword else 0 for x in df[label_name]])\n",
    "X_train, X_test, y_train, y_test = train_test_split(msg_vectors[0:partial], labels[0:partial],\n",
    "                                                    test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardize Input (skip for now)\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ts = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "# Y_train_ts = torch.from_numpy(Y_train).type(torch.LongTensor)\n",
    "# X_test_ts = torch.from_numpy(X_test).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test data\n",
    "class testData(Dataset):    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)#\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer Feed-Forward network with BatchNorm and Dropout\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(300, 1024) \n",
    "        self.layer_2 = nn.Linear(1024, 512)\n",
    "        self.layer_3 = nn.Linear(512, 128)\n",
    "        self.layer_out = nn.Linear(128, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "#         self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "#         self.batchnorm2 = nn.BatchNorm1d(512)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "#         x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "#         x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=300, out_features=1024, bias=True)\n",
      "  (layer_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (layer_3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.33508 | Acc: 85.262\n",
      "Epoch 002: | Loss: 0.29187 | Acc: 87.536\n",
      "Epoch 003: | Loss: 0.28300 | Acc: 87.990\n",
      "Epoch 004: | Loss: 0.27775 | Acc: 88.181\n",
      "Epoch 005: | Loss: 0.27563 | Acc: 88.214\n",
      "Epoch 006: | Loss: 0.27160 | Acc: 88.509\n",
      "Epoch 007: | Loss: 0.26754 | Acc: 88.499\n",
      "Epoch 008: | Loss: 0.26308 | Acc: 88.762\n",
      "Epoch 009: | Loss: 0.26093 | Acc: 88.914\n",
      "Epoch 010: | Loss: 0.25746 | Acc: 88.936\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5503,  1161],\n",
       "       [ 1138, 12198]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      6664\n",
      "           1       0.91      0.91      0.91     13336\n",
      "\n",
      "    accuracy                           0.89     20000\n",
      "   macro avg       0.87      0.87      0.87     20000\n",
      "weighted avg       0.88      0.89      0.89     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_list, word_array, word_occr = get_word_data(nlp,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yelp_glove_word = [word_list, word_array, word_occr]\n",
    "# %store yelp_glove_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stored result\n",
    "%store -r yelp_glove_word\n",
    "word_list = yelp_glove_word[0]\n",
    "word_array = yelp_glove_word[1]\n",
    "word_occr = yelp_glove_word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word data\n",
    "class wordData(Dataset):    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "word_data = wordData(torch.FloatTensor(word_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_loader = DataLoader(dataset=word_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321423/321423 [03:00<00:00, 1783.00it/s]\n"
     ]
    }
   ],
   "source": [
    "word_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in tqdm(word_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        word_pred = model(X_batch)\n",
    "        word_pred_list.append(word_pred.cpu().numpy())\n",
    "word_pred_list = [a.squeeze().tolist() for a in word_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = pd.DataFrame({'word':word_list,'prob':word_pred_list,'occurrence':word_occr})\n",
    "top_words = top_words.sort_values('prob',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 1000\n",
    "pos_words_f = top_words[top_words['occurrence']>thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>prob</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>certified</td>\n",
       "      <td>69.262474</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14162</th>\n",
       "      <td>professionally</td>\n",
       "      <td>65.057510</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>trained</td>\n",
       "      <td>61.979855</td>\n",
       "      <td>2532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>experienced</td>\n",
       "      <td>59.758179</td>\n",
       "      <td>8983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>professional</td>\n",
       "      <td>57.151848</td>\n",
       "      <td>28889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>expert</td>\n",
       "      <td>52.674164</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>finest</td>\n",
       "      <td>47.928219</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>fully</td>\n",
       "      <td>46.041420</td>\n",
       "      <td>4934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>professionals</td>\n",
       "      <td>45.191513</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>technicians</td>\n",
       "      <td>44.697140</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>incredible</td>\n",
       "      <td>44.662304</td>\n",
       "      <td>13612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>pros</td>\n",
       "      <td>44.058449</td>\n",
       "      <td>3886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>amazing</td>\n",
       "      <td>42.766747</td>\n",
       "      <td>130807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>trusted</td>\n",
       "      <td>42.521252</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>knowledgeable</td>\n",
       "      <td>42.023933</td>\n",
       "      <td>16204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word       prob  occurrence\n",
       "5059        certified  69.262474        1010\n",
       "14162  professionally  65.057510        1205\n",
       "125           trained  61.979855        2532\n",
       "2120      experienced  59.758179        8983\n",
       "496      professional  57.151848       28889\n",
       "4211           expert  52.674164        1930\n",
       "3988           finest  47.928219        1035\n",
       "3749            fully  46.041420        4934\n",
       "4729    professionals  45.191513        1404\n",
       "3210      technicians  44.697140        1561\n",
       "2590       incredible  44.662304       13612\n",
       "2113             pros  44.058449        3886\n",
       "313           amazing  42.766747      130807\n",
       "7892          trusted  42.521252        1281\n",
       "1829    knowledgeable  42.023933       16204"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_words_f.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>prob</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>disgusting</td>\n",
       "      <td>-114.519264</td>\n",
       "      <td>6644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>unprofessional</td>\n",
       "      <td>-97.912903</td>\n",
       "      <td>6733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5349</th>\n",
       "      <td>tasteless</td>\n",
       "      <td>-97.151207</td>\n",
       "      <td>3938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9178</th>\n",
       "      <td>disrespectful</td>\n",
       "      <td>-93.768791</td>\n",
       "      <td>1535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9155</th>\n",
       "      <td>disgusted</td>\n",
       "      <td>-82.781464</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>unacceptable</td>\n",
       "      <td>-80.649254</td>\n",
       "      <td>2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>filthy</td>\n",
       "      <td>-80.094994</td>\n",
       "      <td>2455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>horrible</td>\n",
       "      <td>-79.794540</td>\n",
       "      <td>25833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5760</th>\n",
       "      <td>incompetent</td>\n",
       "      <td>-79.603256</td>\n",
       "      <td>1663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6959</th>\n",
       "      <td>miserable</td>\n",
       "      <td>-79.050980</td>\n",
       "      <td>1426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8613</th>\n",
       "      <td>horrendous</td>\n",
       "      <td>-74.002258</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6444</th>\n",
       "      <td>undercooked</td>\n",
       "      <td>-73.249725</td>\n",
       "      <td>2945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>pathetic</td>\n",
       "      <td>-73.206482</td>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9537</th>\n",
       "      <td>soggy</td>\n",
       "      <td>-72.793503</td>\n",
       "      <td>7154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>rude</td>\n",
       "      <td>-71.766861</td>\n",
       "      <td>30652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word        prob  occurrence\n",
       "214       disgusting -114.519264        6644\n",
       "5805  unprofessional  -97.912903        6733\n",
       "5349       tasteless  -97.151207        3938\n",
       "9178   disrespectful  -93.768791        1535\n",
       "9155       disgusted  -82.781464        1377\n",
       "1367    unacceptable  -80.649254        2800\n",
       "4447          filthy  -80.094994        2455\n",
       "984         horrible  -79.794540       25833\n",
       "5760     incompetent  -79.603256        1663\n",
       "6959       miserable  -79.050980        1426\n",
       "8613      horrendous  -74.002258        1154\n",
       "6444     undercooked  -73.249725        2945\n",
       "1252        pathetic  -73.206482        1309\n",
       "9537           soggy  -72.793503        7154\n",
       "1795            rude  -71.766861       30652"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_words_f  = pos_words_f.sort_values('prob',ascending=True)\n",
    "neg_words_f.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
