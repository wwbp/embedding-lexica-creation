{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a new dataset, only modifying the following shall be sufficient. \n",
    "* Import Data\n",
    "    * directory\n",
    "    * file name\n",
    "    * pd.read_csv() if different file type\n",
    "    * data_name\n",
    "    * label_name\n",
    "* Prepare Data\n",
    "    * In get_train_data function, modify the way binary labels are defined.\n",
    "    * Number of posts (iterations) in get_word_data based on your interest\n",
    "* Results\n",
    "    * Modify the way 'keyword' is used based on your binary labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXWy85hSG3ps"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYi2edrSIhlZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xQY8N_XvtGbearJ5X4QryQ</td>\n",
       "      <td>2</td>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UmFMZ8PyXZTY2QcwzsfQYA</td>\n",
       "      <td>1</td>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG2ZaYiOgpr2DK_90pYjNw</td>\n",
       "      <td>5</td>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i6g_oA9Yf9Y31qt0wibXpw</td>\n",
       "      <td>1</td>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6TdNDKywdbjoTkizeMce8A</td>\n",
       "      <td>4</td>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  stars  \\\n",
       "0  xQY8N_XvtGbearJ5X4QryQ      2   \n",
       "1  UmFMZ8PyXZTY2QcwzsfQYA      1   \n",
       "2  LG2ZaYiOgpr2DK_90pYjNw      5   \n",
       "3  i6g_oA9Yf9Y31qt0wibXpw      1   \n",
       "4  6TdNDKywdbjoTkizeMce8A      4   \n",
       "\n",
       "                                                text  \n",
       "0  As someone who has worked with many museums, I...  \n",
       "1  I am actually horrified this place is still in...  \n",
       "2  I love Deagan's. I do. I really do. The atmosp...  \n",
       "3  Dismal, lukewarm, defrosted-tasting \"TexMex\" g...  \n",
       "4  Oh happy day, finally have a Canes near my cas...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/data1/link10/yelp/'\n",
    "file_name = 'df1M.tsv'\n",
    "raw_df = pd.read_csv(directory + file_name, delimiter = '\\t')\n",
    "# remove rows with missing values\n",
    "df = raw_df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'text'\n",
    "label_name = 'stars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000000 data.\n",
      "Labels are: [2 1 5 4 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    449091\n",
       "4    210363\n",
       "1    156690\n",
       "3    104973\n",
       "2     78883\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    'There are {} data.'.format(df.shape[0]),\n",
    "    'Labels are: {}'.format(df[label_name].unique()),\n",
    "    sep = '\\n'\n",
    "    )\n",
    "df[label_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLbPIpy6FBNn"
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "id": "h4H-xS4oRs-M",
    "outputId": "7a860939-7f5a-454b-839d-406aa88fd24d"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBe-lTvJUJ7Y"
   },
   "outputs": [],
   "source": [
    "# load the language model\n",
    "nlp = spacy.load('/data2/link10/models/fasttext/en_fasttext_crawl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dCiBEqP8UxPI",
    "outputId": "51aca1ca-5a26-445b-aa83-f079e2348376"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [10:05<00:00, 1651.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000000, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with nlp.disable_pipes():\n",
    "    msg_vectors = np.array([nlp(msg.lower()).vector for msg in tqdm(df[data_name])])\n",
    "msg_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'yelp_fasttext_vectors' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "yelp_fasttext_vectors = msg_vectors\n",
    "%store yelp_fasttext_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding takes huge amount of time, use stored result\n",
    "%store -r yelp_fasttext_vectors\n",
    "msg_vectors = yelp_fasttext_vectors\n",
    "msg_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "c5sES7qvWfEi",
    "outputId": "6673cdff-b728-41e7-a096-46572ce9ffc8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def get_train_data(keyword):\n",
    "    labels = np.array([1 if x > keyword else 0 for x in df[label_name]])\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(msg_vectors, labels,\n",
    "                                                    test_size=0.2, random_state=1)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_data(npl,df):\n",
    "    word_list = []\n",
    "    word_vec = []\n",
    "    word_occr_dict = {}\n",
    "    with nlp.disable_pipes():\n",
    "        for i in tqdm(range(1000000)):\n",
    "            msg = nlp(df.iloc[i][data_name].lower())\n",
    "            for token in msg:\n",
    "                if token.text not in word_list:\n",
    "                    word_list.append(token.text)\n",
    "                    word_vec.append([token.vector])\n",
    "                    word_occr_dict[token.text] = 1\n",
    "                else:\n",
    "                    word_occr_dict[token.text] += 1     \n",
    "    word_array = np.concatenate(np.array(word_vec),0)\n",
    "    word_occr = [word_occr_dict[word] for word in word_list]\n",
    "    return word_list, word_array, word_occr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4L-Z_EumaiB2"
   },
   "source": [
    "# Linear SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dn1RBXWfamf8",
    "outputId": "38157e38-4ed4-4491-a88b-4190b5ae6bf8"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def top_words_SVC(X_train, X_test, Y_train, Y_test, word_list, word_array, word_occr): \n",
    "# Set dual=False to speed up training, and it's not needed\n",
    "    svc = LinearSVC(random_state=1, dual=False, max_iter=10000)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    accu = svc.score(X_test, Y_test)\n",
    "    scores = svc.decision_function(word_array)\n",
    "    word_df = pd.DataFrame({'word':word_list,'scores':scores,'occurrence':word_occr})\n",
    "#     word_df = word_df[word_df['occurrence']>50]\n",
    "    word_df = word_df.sort_values('scores',ascending=False)\n",
    "    return accu, word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(keyword, word_list, word_array, word_occr):\n",
    "    X_train, X_test, Y_train, Y_test = get_train_data(keyword)\n",
    "    accu, words = top_words_SVC(X_train, X_test, Y_train, Y_test, word_list, word_array, word_occr)\n",
    "    print(\n",
    "        'Critical star: {}'.format(keyword),\n",
    "        'Accuracy: {}'.format(accu),\n",
    "        sep = '\\n'\n",
    "    )\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [2:02:45<00:00, 135.77it/s] \n"
     ]
    }
   ],
   "source": [
    "word_list, word_array, word_occr = get_word_data(nlp,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'yelp_fasttext_word' (list)\n"
     ]
    }
   ],
   "source": [
    "yelp_fasttext_word = [word_list, word_array, word_occr]\n",
    "%store yelp_fasttext_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stored result\n",
    "%store -r yelp_fasttext_word\n",
    "word_list = yelp_fasttext_word[0]\n",
    "word_array = yelp_fasttext_word[1]\n",
    "word_occr = yelp_fasttext_word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext + linear SVC + filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical star: 3\n",
      "Accuracy: 0.88954\n"
     ]
    }
   ],
   "source": [
    "top_words = get_top_words(3,word_list, word_array, word_occr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 1000\n",
    "pos_words_f = top_words[top_words['occurrence']>thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>scores</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>knowledgeable</td>\n",
       "      <td>23.677865</td>\n",
       "      <td>16204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>superb</td>\n",
       "      <td>23.409851</td>\n",
       "      <td>4944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6425</th>\n",
       "      <td>knowledgable</td>\n",
       "      <td>22.175282</td>\n",
       "      <td>2868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>terrific</td>\n",
       "      <td>22.064291</td>\n",
       "      <td>3998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>pleasure</td>\n",
       "      <td>20.893980</td>\n",
       "      <td>4677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>fabulous</td>\n",
       "      <td>20.276752</td>\n",
       "      <td>9754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>20.043213</td>\n",
       "      <td>37654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>amazing</td>\n",
       "      <td>19.977137</td>\n",
       "      <td>130807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>fantastic</td>\n",
       "      <td>19.934197</td>\n",
       "      <td>36577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>gorgeous</td>\n",
       "      <td>19.838303</td>\n",
       "      <td>5277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7373</th>\n",
       "      <td>energetic</td>\n",
       "      <td>19.830604</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5598</th>\n",
       "      <td>responsive</td>\n",
       "      <td>19.824072</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>beautifully</td>\n",
       "      <td>19.573440</td>\n",
       "      <td>4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>delight</td>\n",
       "      <td>19.256025</td>\n",
       "      <td>2608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>19.183077</td>\n",
       "      <td>4909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word     scores  occurrence\n",
       "1829  knowledgeable  23.677865       16204\n",
       "3983         superb  23.409851        4944\n",
       "6425   knowledgable  22.175282        2868\n",
       "4995       terrific  22.064291        3998\n",
       "1862       pleasure  20.893980        4677\n",
       "3429       fabulous  20.276752        9754\n",
       "84        wonderful  20.043213       37654\n",
       "313         amazing  19.977137      130807\n",
       "929       fantastic  19.934197       36577\n",
       "1173       gorgeous  19.838303        5277\n",
       "7373      energetic  19.830604        1027\n",
       "5598     responsive  19.824072        2009\n",
       "2561    beautifully  19.573440        4020\n",
       "2019        delight  19.256025        2608\n",
       "4224        relaxed  19.183077        4909"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_words_f.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>scores</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5349</th>\n",
       "      <td>tasteless</td>\n",
       "      <td>-37.372035</td>\n",
       "      <td>3938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>flavorless</td>\n",
       "      <td>-35.978347</td>\n",
       "      <td>2531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6321</th>\n",
       "      <td>inedible</td>\n",
       "      <td>-34.455828</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6444</th>\n",
       "      <td>undercooked</td>\n",
       "      <td>-34.410932</td>\n",
       "      <td>2945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>unprofessional</td>\n",
       "      <td>-34.119944</td>\n",
       "      <td>6733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tacky</td>\n",
       "      <td>-31.303869</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9178</th>\n",
       "      <td>disrespectful</td>\n",
       "      <td>-31.126935</td>\n",
       "      <td>1535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>disgusting</td>\n",
       "      <td>-30.882839</td>\n",
       "      <td>6644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>unacceptable</td>\n",
       "      <td>-30.660224</td>\n",
       "      <td>2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>lackluster</td>\n",
       "      <td>-30.618109</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>pathetic</td>\n",
       "      <td>-30.354959</td>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>bland</td>\n",
       "      <td>-29.766503</td>\n",
       "      <td>16126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>overcooked</td>\n",
       "      <td>-29.741645</td>\n",
       "      <td>4957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9155</th>\n",
       "      <td>disgusted</td>\n",
       "      <td>-29.713008</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>subpar</td>\n",
       "      <td>-28.768199</td>\n",
       "      <td>1754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word     scores  occurrence\n",
       "5349       tasteless -37.372035        3938\n",
       "2270      flavorless -35.978347        2531\n",
       "6321        inedible -34.455828        1991\n",
       "6444     undercooked -34.410932        2945\n",
       "5805  unprofessional -34.119944        6733\n",
       "203            tacky -31.303869        1082\n",
       "9178   disrespectful -31.126935        1535\n",
       "214       disgusting -30.882839        6644\n",
       "1367    unacceptable -30.660224        2800\n",
       "1126      lackluster -30.618109        1156\n",
       "1252        pathetic -30.354959        1309\n",
       "787            bland -29.766503       16126\n",
       "2126      overcooked -29.741645        4957\n",
       "9155       disgusted -29.713008        1377\n",
       "5156          subpar -28.768199        1754"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_words_f  = pos_words_f.sort_values('scores',ascending=True)\n",
    "neg_words_f.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "amazon_fasttext_vectors             -> array([[-0.08999809, -0.09236344, -0.05310385, ...\n",
      "amazon_fasttext_word                -> [['i', 'have', 'bought', 'several', 'of', 'the', '\n",
      "nrc_fasttext_vectors                -> array([[ 0.01679   , -0.15144   , -0.02061   , ...\n",
      "nrc_fasttext_word                   -> [['thinks', 'that', '@melbahughes', 'had', 'a', 'g\n",
      "nrc_glove_vectors                   -> array([[ 0.04746217,  0.181698  ,  0.01058619, ...\n",
      "nrc_glove_word                      -> [['thinks', 'that', '@melbahughes', 'had', 'a', 'g\n",
      "yelp_fasttext_vectors               -> array([[-0.03174149, -0.02313265, -0.01704215, ...\n",
      "yelp_fasttext_word                  -> [['as', 'someone', 'who', 'has', 'worked', 'with',\n",
      "yelp_glove_vectors                  -> array([[-8.77902319e-04,  1.61974162e-01, -1.50082\n",
      "yelp_glove_word                     -> [['as', 'someone', 'who', 'has', 'worked', 'with',\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
