{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a new dataset, only modifying the following shall be sufficient. \n",
    "* Import Data\n",
    "    * directory\n",
    "    * file name\n",
    "    * pd.read_csv() if different file type\n",
    "    * data_name\n",
    "    * label_name\n",
    "* Prepare Data\n",
    "    * In get_train_data function, modify the way binary labels are defined.\n",
    "    * Number of posts (iterations) in get_word_data based on your interest\n",
    "* Results\n",
    "    * Modify the way 'keyword' is used based on your binary labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXWy85hSG3ps"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYi2edrSIhlZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xQY8N_XvtGbearJ5X4QryQ</td>\n",
       "      <td>2</td>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UmFMZ8PyXZTY2QcwzsfQYA</td>\n",
       "      <td>1</td>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG2ZaYiOgpr2DK_90pYjNw</td>\n",
       "      <td>5</td>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i6g_oA9Yf9Y31qt0wibXpw</td>\n",
       "      <td>1</td>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6TdNDKywdbjoTkizeMce8A</td>\n",
       "      <td>4</td>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  stars  \\\n",
       "0  xQY8N_XvtGbearJ5X4QryQ      2   \n",
       "1  UmFMZ8PyXZTY2QcwzsfQYA      1   \n",
       "2  LG2ZaYiOgpr2DK_90pYjNw      5   \n",
       "3  i6g_oA9Yf9Y31qt0wibXpw      1   \n",
       "4  6TdNDKywdbjoTkizeMce8A      4   \n",
       "\n",
       "                                                text  \n",
       "0  As someone who has worked with many museums, I...  \n",
       "1  I am actually horrified this place is still in...  \n",
       "2  I love Deagan's. I do. I really do. The atmosp...  \n",
       "3  Dismal, lukewarm, defrosted-tasting \"TexMex\" g...  \n",
       "4  Oh happy day, finally have a Canes near my cas...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/data2/link10/data/yelp/'\n",
    "file_name = 'df1M.tsv'\n",
    "raw_df = pd.read_csv(directory + file_name, delimiter = '\\t')\n",
    "# remove rows with missing values\n",
    "df = raw_df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'text'\n",
    "label_name = 'stars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OaP5UXK6HM4H",
    "outputId": "099b63c3-bc99-40c6-9726-79edc3e721eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000000 data.\n",
      "Labels are: [2 1 5 4 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    449091\n",
       "4    210363\n",
       "1    156690\n",
       "3    104973\n",
       "2     78883\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    'There are {} data.'.format(df.shape[0]),\n",
    "    'Labels are: {}'.format(df[label_name].unique()),\n",
    "    sep = '\\n'\n",
    "    )\n",
    "df[label_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLbPIpy6FBNn"
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "id": "h4H-xS4oRs-M",
    "outputId": "7a860939-7f5a-454b-839d-406aa88fd24d"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBe-lTvJUJ7Y"
   },
   "outputs": [],
   "source": [
    "# load the language model\n",
    "nlp = spacy.load('/data2/link10/models/fasttext/en_fasttext_crawl_subword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dCiBEqP8UxPI",
    "outputId": "51aca1ca-5a26-445b-aa83-f079e2348376"
   },
   "outputs": [],
   "source": [
    "with nlp.disable_pipes():\n",
    "    msg_vectors = np.array([nlp(msg.lower()).vector for msg in tqdm(df[data_name])])\n",
    "msg_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_fasttext_vectors_subword = msg_vectors\n",
    "%store yelp_fasttext_vectors_subword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding takes huge amount of time, use stored result\n",
    "%store -r yelp_fasttext_vectors_subword\n",
    "msg_vectors = yelp_fasttext_vectors_subword\n",
    "msg_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "c5sES7qvWfEi",
    "outputId": "6673cdff-b728-41e7-a096-46572ce9ffc8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def get_train_data(keyword):\n",
    "    labels = np.array([1 if x > keyword else 0 for x in df[label_name]])\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(msg_vectors, labels,\n",
    "                                                    test_size=0.2, random_state=1)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_data(npl,df):\n",
    "    word_list = []\n",
    "    word_vec = []\n",
    "    word_occr_dict = {}\n",
    "    with nlp.disable_pipes():\n",
    "        for i in tqdm(range(1000000)):\n",
    "            msg = nlp(df.iloc[i][data_name].lower())\n",
    "            for token in msg:\n",
    "                if token.text not in word_list:\n",
    "                    word_list.append(token.text)\n",
    "                    word_vec.append([token.vector])\n",
    "                    word_occr_dict[token.text] = 1\n",
    "                else:\n",
    "                    word_occr_dict[token.text] += 1     \n",
    "    word_array = np.concatenate(np.array(word_vec),0)\n",
    "    word_occr = [word_occr_dict[word] for word in word_list]\n",
    "    return word_list, word_array, word_occr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4L-Z_EumaiB2"
   },
   "source": [
    "# Linear SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dn1RBXWfamf8",
    "outputId": "38157e38-4ed4-4491-a88b-4190b5ae6bf8"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def top_words_SVC(X_train, X_test, Y_train, Y_test, word_list, word_array, word_occr): \n",
    "# Set dual=False to speed up training, and it's not needed\n",
    "    svc = LinearSVC(random_state=1, dual=False, max_iter=10000)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    accu = svc.score(X_test, Y_test)\n",
    "    scores = svc.decision_function(word_array)\n",
    "    word_df = pd.DataFrame({'word':word_list,'scores':scores,'occurrence':word_occr})\n",
    "#     word_df = word_df[word_df['occurrence']>50]\n",
    "    word_df = word_df.sort_values('scores',ascending=False)\n",
    "    return accu, word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(keyword, word_list, word_array, word_occr):\n",
    "    X_train, X_test, Y_train, Y_test = get_train_data(keyword)\n",
    "    accu, words = top_words_SVC(X_train, X_test, Y_train, Y_test, word_list, word_array, word_occr)\n",
    "    print(\n",
    "        'Critical star: {}'.format(keyword),\n",
    "        'Accuracy: {}'.format(accu),\n",
    "        sep = '\\n'\n",
    "    )\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [1:39:29<00:00, 167.51it/s]\n"
     ]
    }
   ],
   "source": [
    "word_list, word_array, word_occr = get_word_data(nlp,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'yelp_fasttext_word_subword' (list)\n"
     ]
    }
   ],
   "source": [
    "yelp_fasttext_word_subword = [word_list, word_array, word_occr]\n",
    "%store yelp_fasttext_word_subword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stored result\n",
    "%store -r yelp_fasttext_word_subword\n",
    "word_list = yelp_fasttext_word_subword[0]\n",
    "word_array = yelp_fasttext_word_subword[1]\n",
    "word_occr = yelp_fasttext_word_subword[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext_subword + linear SVC + filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical star: 3\n",
      "Accuracy: 0.881965\n"
     ]
    }
   ],
   "source": [
    "top_words = get_top_words(3,word_list, word_array, word_occr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 1000\n",
    "pos_words_f = top_words[top_words['occurrence']>thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>scores</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>fav</td>\n",
       "      <td>32.910557</td>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>joy</td>\n",
       "      <td>27.102466</td>\n",
       "      <td>1754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7553</th>\n",
       "      <td>x</td>\n",
       "      <td>26.820804</td>\n",
       "      <td>3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8941</th>\n",
       "      <td>fave</td>\n",
       "      <td>22.610263</td>\n",
       "      <td>2247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8587</th>\n",
       "      <td>~</td>\n",
       "      <td>22.225642</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>gem</td>\n",
       "      <td>21.945507</td>\n",
       "      <td>11036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6848</th>\n",
       "      <td>à</td>\n",
       "      <td>19.636158</td>\n",
       "      <td>5490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>cozy</td>\n",
       "      <td>19.467758</td>\n",
       "      <td>7961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>yum</td>\n",
       "      <td>19.011517</td>\n",
       "      <td>11546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>tom</td>\n",
       "      <td>18.900867</td>\n",
       "      <td>3815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>superb</td>\n",
       "      <td>18.757697</td>\n",
       "      <td>4944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>bon</td>\n",
       "      <td>18.661180</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>hop</td>\n",
       "      <td>17.337629</td>\n",
       "      <td>2302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>fun</td>\n",
       "      <td>16.945411</td>\n",
       "      <td>47157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>dj</td>\n",
       "      <td>16.506699</td>\n",
       "      <td>4279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word     scores  occurrence\n",
       "3631     fav  32.910557        2525\n",
       "7519     joy  27.102466        1754\n",
       "7553       x  26.820804        3099\n",
       "8941    fave  22.610263        2247\n",
       "8587       ~  22.225642        1244\n",
       "4707     gem  21.945507       11036\n",
       "6848       à  19.636158        5490\n",
       "68      cozy  19.467758        7961\n",
       "3340     yum  19.011517       11546\n",
       "5998     tom  18.900867        3815\n",
       "3983  superb  18.757697        4944\n",
       "4499     bon  18.661180        2063\n",
       "975      hop  17.337629        2302\n",
       "976      fun  16.945411       47157\n",
       "3291      dj  16.506699        4279"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_words_f.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>scores</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>rude</td>\n",
       "      <td>-33.204613</td>\n",
       "      <td>30652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tacky</td>\n",
       "      <td>-30.649772</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>bland</td>\n",
       "      <td>-27.704997</td>\n",
       "      <td>16126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>stale</td>\n",
       "      <td>-27.080081</td>\n",
       "      <td>3705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>ugly</td>\n",
       "      <td>-26.341043</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7626</th>\n",
       "      <td>lied</td>\n",
       "      <td>-25.167316</td>\n",
       "      <td>2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>poor</td>\n",
       "      <td>-24.543460</td>\n",
       "      <td>17567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>0</td>\n",
       "      <td>-23.725654</td>\n",
       "      <td>3518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>ok</td>\n",
       "      <td>-23.618393</td>\n",
       "      <td>48327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>waste</td>\n",
       "      <td>-23.406361</td>\n",
       "      <td>11468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>ugh</td>\n",
       "      <td>-22.706421</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>meh</td>\n",
       "      <td>-22.573969</td>\n",
       "      <td>5566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>rudely</td>\n",
       "      <td>-22.347918</td>\n",
       "      <td>2062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>lame</td>\n",
       "      <td>-22.062230</td>\n",
       "      <td>1623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>crap</td>\n",
       "      <td>-21.489512</td>\n",
       "      <td>5179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word     scores  occurrence\n",
       "1795    rude -33.204613       30652\n",
       "203    tacky -30.649772        1082\n",
       "787    bland -27.704997       16126\n",
       "1450   stale -27.080081        3705\n",
       "5021    ugly -26.341043        1406\n",
       "7626    lied -25.167316        2052\n",
       "864     poor -24.543460       17567\n",
       "4214       0 -23.725654        3518\n",
       "1041      ok -23.618393       48327\n",
       "854    waste -23.406361       11468\n",
       "3116     ugh -22.706421        2022\n",
       "3129     meh -22.573969        5566\n",
       "3610  rudely -22.347918        2062\n",
       "2689    lame -22.062230        1623\n",
       "3553    crap -21.489512        5179"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_words_f  = pos_words_f.sort_values('scores',ascending=True)\n",
    "neg_words_f.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
