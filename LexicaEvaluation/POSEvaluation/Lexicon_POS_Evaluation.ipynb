{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import en_core_web_lg\n",
    "\n",
    "# from spacy.tokenizer import Tokenizer\n",
    "dataFolder = '/data2/Datasets/Raw'\n",
    "\n",
    "import operator\n",
    "import sys\n",
    "sys.path.insert(0,'/data2/Datasets/')\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_lg==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz#egg=en_core_web_lg==2.3.1 in /home/tjss/miniconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/tjss/miniconda3/lib/python3.7/site-packages (from en_core_web_lg==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.47.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.9.6)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (49.2.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.19.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/tjss/miniconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/tjss/miniconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tjss/miniconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/tjss/miniconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/tjss/miniconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/tjss/miniconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/tjss/miniconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19338/19338 [02:42<00:00, 119.30it/s]\n",
      "100%|██████████| 19338/19338 [02:43<00:00, 117.99it/s]\n",
      "100%|██████████| 19338/19338 [02:43<00:00, 118.14it/s]\n",
      "100%|██████████| 19338/19338 [02:43<00:00, 118.08it/s]\n",
      "100%|██████████| 19338/19338 [02:43<00:00, 118.31it/s]\n",
      "100%|██████████| 10000/10000 [03:14<00:00, 51.52it/s]\n",
      "100%|██████████| 10000/10000 [02:41<00:00, 61.78it/s]\n",
      "100%|██████████| 10000/10000 [03:39<00:00, 45.56it/s]\n",
      "100%|██████████| 1860/1860 [00:40<00:00, 46.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# GETTING POS TAGS(majority voting) OF WORDS FROM ORIGINAL DATASETS\n",
    "lexiconDatasetList = [\"nrc_joy\", \"nrc_sadness\", \"nrc_anger\", \"nrc_fear\", \"nrc_surprise\", \"amazon_toys_subset\",\"amazon_finefood_subset\", \"yelp_subset\", \"empathy\"]\n",
    "\n",
    "final_pos_dicts = {}\n",
    "for lexiconDataset in lexiconDatasetList:\n",
    "    token_pos_dict = {}\n",
    "    token_freq_dict = {}\n",
    "    final_token_pos_dict = {}\n",
    "\n",
    "    totalDF = getData(dataFolder,lexiconDataset)\n",
    "    nlp = en_core_web_lg.load()\n",
    "\n",
    "    with nlp.disable_pipes():\n",
    "        for msg in tqdm(totalDF[\"text\"]): \n",
    "            doc = nlp(msg)\n",
    "            for tkn in doc:\n",
    "                if str(tkn) not in token_pos_dict:\n",
    "                    token_pos_dict[str(tkn)] = {}\n",
    "\n",
    "                if str(tkn) not in token_freq_dict:\n",
    "                    token_freq_dict[str(tkn)] = 0\n",
    "                token_freq_dict[str(tkn)] += 1\n",
    "\n",
    "                if tkn.pos_ not in token_pos_dict[tkn.text]:\n",
    "                    token_pos_dict[str(tkn)][tkn.pos_]=0\n",
    "                token_pos_dict[str(tkn)][tkn.pos_]+=1\n",
    "\n",
    "\n",
    "    for tkn in token_pos_dict:\n",
    "        final_token_pos_dict[tkn] = max(token_pos_dict[tkn].items(), key=operator.itemgetter(1))[0]\n",
    "    final_pos_dicts[lexiconDataset] = final_token_pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BERT_Mask       DistilBERT_Mask       FFN           LSTM\n",
    "# BERT_Partition  DistilBERT_Partition  FFN_DeepShap  SVM\n",
    "# method_path_name =\"DistilBERT_Mask/\"\n",
    "# lexica_path = \"~/Final/embedding-lexica-creation/lexica/\"\n",
    "# curr_lex = \"yelp_subset\"\n",
    "# csv_file_name = \"yelp_subset_distilbert_regression_mask.csv\"\n",
    "# text_name = \"Word\"\n",
    "\n",
    "\n",
    "def calculatePOSStatistics(method_path_name, lexica_path, curr_lex, text_name):\n",
    "    lexica =  pd.read_csv(lexica_path+method_path_name+csv_file_name)\n",
    "    pos_freq_dict = {'PRON':0, 'AUX':0, 'ADV':0, 'VERB':0, 'PART':0, 'ADP':0, 'DET':0, 'NOUN':0, 'PUNCT':0, 'SPACE':0, 'ADJ':0, 'CCONJ':0, 'SCONJ':0, 'PROPN':0, 'NUM':0,'INTJ':0, 'X':0, 'SYM':0,'UNCLSFD':0, 'valid_count':0}\n",
    "    total_valid_count = 0    \n",
    "    words_not_found =[]\n",
    "\n",
    "    for word in tqdm(lexica[text_name]): \n",
    "        if word not in final_pos_dicts[curr_lex]:\n",
    "            pos_freq_dict[\"UNCLSFD\"]+=1\n",
    "        else:\n",
    "            pos_freq_dict[final_pos_dicts[curr_lex][word]]+=1\n",
    "            total_valid_count+=1\n",
    "    return pos_freq_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23283/23283 [00:00<00:00, 643939.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PRON': 54, 'AUX': 19, 'ADV': 722, 'VERB': 3756, 'PART': 6, 'ADP': 76, 'DET': 38, 'NOUN': 8176, 'PUNCT': 88, 'SPACE': 0, 'ADJ': 2672, 'CCONJ': 10, 'SCONJ': 20, 'PROPN': 1402, 'NUM': 792, 'INTJ': 114, 'X': 326, 'SYM': 5, 'UNCLSFD': 5007, 'valid_count': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CHANGE path name, lexica path, curr lex, csv filename and text name here and RUN\n",
    "\n",
    "method_path_name =\"DistilBERT_Mask/\"\n",
    "lexica_path = \"~/Final/embedding-lexica-creation/lexica/\"\n",
    "curr_lex = \"yelp_subset\"\n",
    "csv_file_name = \"yelp_subset_distilbert_regression_mask.csv\"\n",
    "text_name = \"Word\"\n",
    "\n",
    "print(calculatePOSStatistics(method_path_name, lexica_path, curr_lex, text_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
